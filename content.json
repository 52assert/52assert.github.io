{"meta":{"title":"Dream","subtitle":"","description":"","author":"Aurora","url":"https://blog.this52.cn","root":"/"},"pages":[{"title":"","date":"2020-10-28T12:03:15.996Z","updated":"2020-09-26T10:54:04.000Z","comments":true,"path":"about/index.html","permalink":"https://blog.this52.cn/about/index.html","excerpt":"","text":""},{"title":"","date":"2020-10-28T12:03:15.921Z","updated":"2020-09-26T12:54:00.000Z","comments":true,"path":"404.html","permalink":"https://blog.this52.cn/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2020-10-28T12:03:16.177Z","updated":"2020-09-26T13:42:20.000Z","comments":true,"path":"categories/index.html","permalink":"https://blog.this52.cn/categories/index.html","excerpt":"","text":""},{"title":"伙伴们","date":"2020-10-28T12:03:16.239Z","updated":"2020-09-26T14:22:00.000Z","comments":true,"path":"friends/index.html","permalink":"https://blog.this52.cn/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-10-28T12:03:16.294Z","updated":"2020-09-26T13:41:40.000Z","comments":true,"path":"tags/index.html","permalink":"https://blog.this52.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"MongoDB随记","slug":"MongoDB随记","date":"2020-10-25T12:18:08.000Z","updated":"2020-10-25T12:18:08.000Z","comments":true,"path":"posts/20c0704e/","link":"","permalink":"https://blog.this52.cn/posts/20c0704e/","excerpt":"","text":"MongoDB简介MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB安装1.配置yum源123456789vim /etc/yum.repos.d/mongodb-org-4.0.repo# 配置[mongodb-org-4.0]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/#releasever/mongodb-org/4.0/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-4.0.asc 2.yum安装1sudo yum install -y mongodb-org 3.相关命令12345678910111213# 启动|重启|关闭systemctl start|restart|stop mongod# 查看进程ps -aux | grep mongod# 卸载MongoDBsudo yum erase $(rpm -qa | grep mongodb-org)sudo rm -r /var/log/mongodb # 删除日志文件sudo rm -r /var/lib/mongo # 删除数据文件# 验证服务mongo 4.配置远程连接12345vim /etc/mongod.conf# bind修改为0.0.0.0service mongod restart # 重启服务 必须开放27017端口或者关闭防火墙，否则无法连接 MongoDB基本操作1.插入查找123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// 列出所有集合db.getCollectionNames();// 插入一条数据并创建表db.users.insert(&#123;username:&quot;zs&quot;,age:&quot;3&quot;,height:&quot;180&quot;&#125;);// 插入多条数据db.users.insert([&#123;username:&quot;zs&quot;,age:&quot;3&quot;,height:&quot;180&quot;&#125;,&#123;username:&quot;ls&quot;,age:&quot;4&quot;,height:&quot;155&quot;&#125;,&#123;username:&quot;ww&quot;,age:&quot;5&quot;,height:&quot;158&quot;&#125;,]);db.users.insert([&#123;username:&quot;zs2&quot;,age:3,height:140&#125;,&#123;username:&quot;zs3&quot;,age:13,height:150&#125;,&#123;username:&quot;zs4&quot;,age:23,height:170&#125;,&#123;username:&quot;zs5&quot;,age:33,height:160&#125;,]);// 查 集合.find（&#123;字段：值&#125;）db.users.find();db.users.find(&#123;username:&quot;zs&quot;&#125;)// 大于 $gt 小于 $lt 大于等于 $gte 相等 $eq 不等 $ne 取反 $not(注意数字和字符串)db.users.find(&#123; age:&#123; $not:&#123; $eq:&quot;5&quot; &#125; &#125;&#125;);// 查询条件匹配的数据db.users.find(&#123; age:&#123; $in:[13,33] &#125;&#125;);// 查询条件不匹配的数据db.users.find(&#123; age:&#123; $nin:[13,33] &#125;&#125;);// 查询条件完全匹配的数据db.users.find(&#123; happies:&#123; $all:[&quot;读书&quot;,&quot;&quot;] &#125;&#125;);// 正则查找 ig：忽略大小局并全局db.users.find(&#123; username:&#123; $regex:/zs/ig &#125;&#125;);// 多条件 与db.users.find(&#123; age:&#123;$gte:13&#125;, username:&#123;$eq:&quot;zs3&quot;&#125;&#125;);db.users.find(&#123; age:&#123;$gte:&quot;13&quot;&#125;, username:&#123;$regex:/ZS/ig&#125;&#125;);// 多条件 或db.users.find(&#123; $or:[ &#123;age:&#123;$gte:13&#125;&#125;, &#123;username:&#123;$eq:&quot;ww&quot;&#125;&#125;]&#125;);// 取出3条数据db.users.find().limit(3);// 跳过3条数据db.users.find().skip(3).limit(3);// 排序 1升序-1降序db.users.find().sort(&#123;age:1&#125;);db.users.find().sort(&#123;age:-1&#125;); 2.更新12345678910111213141516171819202122232425262728293031323334// 更新 $setdb.users.update( &#123;username:&quot;zs&quot;&#125;, &#123;$set:&#123;age:1&#125;&#125;);// 自增3 $incdb.users.update( &#123;username:&quot;zs&quot;&#125;, &#123;$inc:&#123;age:3&#125;&#125;);// 删除年龄 $unset (值随意)db.users.update( &#123;username:&quot;zs&quot;&#125;, &#123;$unset:&#123;age:1&#125;&#125;);// 往数组里面添加值 $pushdb.users.update( &#123;username:&quot;zs&quot;&#125;, &#123;$push:&#123;age:123&#125;&#125;);// 删除数组里面的值 $pop(-1从左边删，1从右)db.users.update( &#123;username:&quot;zs&quot;&#125;, &#123;$pop:&#123;age:-1&#125;&#125;);// 删除数组里面具体的值 $pulldb.users.update( &#123;username:&quot;zs&quot;&#125;, &#123;$pull:&#123;age:123&#125;&#125;);","categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.this52.cn/categories/MongoDB/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.this52.cn/tags/MongoDB/"}]},{"title":"VirtualBox使用随记","slug":"VirtualBox使用随记","date":"2020-10-15T16:00:00.000Z","updated":"2020-10-15T16:00:00.000Z","comments":true,"path":"posts/89c0e8d2/","link":"","permalink":"https://blog.this52.cn/posts/89c0e8d2/","excerpt":"","text":"1.安装VirtualBox官网下载Download deepin &amp;&amp; ubuntu 12345# 安装sudo apt install virtualbox# 卸载sudo apt remove pool/main/v/virtualbox/ 2.下载Centos镜像阿里云镜像站https://mirrors.aliyun.com/centos/?spm=a2c6h.13651104.0.0.562e12b2jFtq9hv 开发下载Minimal版本即可， 3.创建虚拟机 这里内存看着给，建议1G以上 此时还需要配置双网卡，否则宿主机无法访问虚拟机 首先进入主机网络管理 创建一个网卡，默认192.168.56.1 关闭 4.配置虚拟机 Save保存 Done begin installation 安装好后Reboot 5.配置网络 此时enp0s8网卡未开启，虚拟机可以ping通外网和宿主机，但是宿主机无法ping通虚拟机。 配置网卡 vi /etc/sysconfig/network-scripts/ifcfg-enp0s8 修改ONBOOT为yes，保存退出 systemctl restart network重启网卡 并查看ip enp0s8网卡已经开启，并且有了刚刚配置的ip 192.168.156.100 此时用宿主机ping虚拟机测试 ssh连接测试 连接成功！ 此时虚拟机可以访问外网，可以访问宿主机，虚拟机间可以互相访问，宿主机也可以访问虚拟机 6.拓展1234567891011121314VBoxManage modifymedium [disk|dvd|floppy] &lt;uuid|filename&gt; [--type normal|writethrough|immutable|shareable| readonly|multiattach] [--autoreset on|off] [--property &lt;name=[value]&gt;] [--compact] [--resize &lt;megabytes&gt;|--resizebyte &lt;bytes&gt;] [--move &lt;path&gt;] [--setlocation &lt;path&gt;] [--description &lt;description string&gt;]# # 修改磁盘大小（图形化没有修改操作）VBoxManage modifymedium /media/aurora/05579a1d-c30b-4e3a-9d18-9bc9dfe08859/VirtualBox VMs/centos-test/centos-test.vdi --resize 30720 # 修改磁盘大小为30G","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/categories/Linux/"}],"tags":[{"name":"VirtualBox","slug":"VirtualBox","permalink":"https://blog.this52.cn/tags/VirtualBox/"}]},{"title":"RabbitMQ随记","slug":"RabbitMQ随记","date":"2020-09-13T08:34:45.000Z","updated":"2020-10-01T13:35:00.000Z","comments":true,"path":"posts/fc3e507b/","link":"","permalink":"https://blog.this52.cn/posts/fc3e507b/","excerpt":"","text":"1.MQ引言1.1什么是MQMQ全称为Message Queue, 消息队列（MQ）是一种应用程序对应用程序的通信方法。消息队列可以简单理解为：把要传输的数据放在队列中，mq 就是存放和发送消息的这么一个队列中间件。在消息队列中，把数据放到消息队列的角色叫做 生产者，从消息队列中消费获取数据的叫做 消费者。 MQ和JMS类似，但不同的是JMS是SUN Java消息中间件服务的一个标准和API定义，而MQ则是遵循了AMQP协议的具体实现和产品 1.2常见MQ较为成熟的MQ产品有IBM WebSphere MQ、RabbitMQ 、ZeroMQ 、ActiveMQ、Redis（当做一个轻量级的队列服务来使用）、Kafka、RocketMQ 1.3不同MQ特点12345678910111213# 1.ActiveMQActiveMQ是Apache出品，最流行的，能力强劲的开源消息总线。它是一个完全支持JMS规范的的消息中间件。丰富的API, 多种集群架构模式让ActiveMQ在业界成为老牌的消息中间件，在中小型企业颇受欢迎!# 2.KafkaKafka是LinkedIn开源的分布式发布-订阅消息系统，目前归属于Apache顶级项目。Kafka主要特点是基于Pu11的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输。0. 8版本开始支持复制，不支持事务， 对消息的重复、丢失、错误没有严格要求，适合产生大量数据的互联网服务的数据收集业务。# 3.RocketMQRocketMQ是阿里开源的消息中间件，它是纯Java开发， 具有高吞吐量、高可用性、适合大规模分布式系统应用的特点。RocketMQ思路起源于Kafka,但并不是Kafka的一个Copy,它对消息的可靠传输及事务性做了优化，目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binglog分发等场景。# 4.RabbitMQRabbitMQ是使用Erlang语言开发的开源消息队列系统，基于AMQP协议来实现。AMQP的主要特征是面向消息、队列、路由(包括点对点和发布/订阅)、 可靠性、安全。AMQP协议更多用在企业系统内对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次。RabbitMQ比Kafka可靠，Kafka更适合IO高吞吐的处理，一般应用在大数据日志处理或对实时性(少量延迟)，可靠性(少量丢数据)要求稍低的场景使用，比如ELK日志收集。 2.RabbitMQ引言2.1RabbitMQ RabbitMQ轻巧，易于在内部和云中部署。它支持多种消息传递协议。RabbitMQ可以部署在分布式和联合配置中，以满足大规模，高可用性的要求 2.2RabbitMQ安装rabbitmq和erlang要对应 1234567891011121314151617181920212223242526272829# 1.上传安装包rabbitmq-server-3.7.28-1.el7.noarch.rpmerlang-22.3.4.10-1.el7.x86_64.rpm# 2.安装erlang依赖包[root@localhost custom]# rpm -ivh erlang-22.3.4.10-1.el7.x86_64.rpmwarning: erlang-22.3.4.10-1.el7.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID 6026dfca: NOKEYPreparing... ################################# [100%]Updating / installing... 1:erlang-22.3.4.10-1.el7 ################################# [100%]# 3.安装rabbitmq[root@localhost custom]# rpm -ivh rabbitmq-server-3.7.28-1.el7.noarch.rpmwarning: rabbitmq-server-3.7.28-1.el7.noarch.rpm: Header V4 RSA/SHA256 Signature, key ID 6026dfca: NOKEYerror: Failed dependencies: socat is needed by rabbitmq-server-3.7.28-1.el7.noarch# 出现此错误是因为依赖包的问题 使用rpm -ivh --nodeps 解决[root@localhost custom]# rpm -ivh --nodeps rabbitmq-server-3.7.28-1.el7.noarch.rpmwarning: rabbitmq-server-3.7.28-1.el7.noarch.rpm: Header V4 RSA/SHA256 Signature, key ID 6026dfca: NOKEYPreparing... ################################# [100%]Updating / installing... 1:rabbitmq-server-3.7.28-1.el7 ################################# [100%]# 4.复制配置文件[root@localhost custom]# cp /usr/share/doc/rabbitmq-server-3.7.28/rabbitmq.config.example /etc/rabbitmq/rabbitmq.config# 5.修改配置文件[root@localhost custom]# vim /etc/rabbitmq/rabbitmq.config 去掉%%以及最后的， 12# 6.启动RabbitMQ[root@localhost custom]# systemctl start rabbitmq-server 12345678# rabbitmq服务相关命令systemctl start|restart|stop|status rabbitmq-server# 设置开启启动systemctl enable rabbitmq-serverrabbitmqctl help # 查看命令帮助文档# 插件管理命令行rabbitmq-pkugins enable|list|disable 启动服务时一直卡主，但是服务却能够使用，查看状态时也不正常 12# 安装socat后解决yum install socat 3.RabbitMQ配置3.1开启web管理页面123456789101112131415161718192021# 1.启动网页版rabbitmq管理插件[root@localhost custom]# rabbitmq-plugins enable rabbitmq_managementEnabling plugins on node rabbit@localhost:rabbitmq_managementThe following plugins have been configured: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchApplying plugin configuration to rabbit@localhost...The following plugins have been enabled: rabbitmq_management rabbitmq_management_agent rabbitmq_web_dispatchset 3 plugins.Offline change; changes will take effect at broker restart.# 2.测试http://192.168.45.121:15672guestguest 3.2添加Virtual Hosts 3.3添加Users 3.4设置Permission 4.RabbitMQ快速上手4.1RabbitMQ支持的消息模型 4.2引入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.rabbitmq&lt;/groupId&gt; &lt;artifactId&gt;amqp-client&lt;/artifactId&gt; &lt;version&gt;5.8.0&lt;/version&gt;&lt;/dependency&gt; 4.3第一种模型（直连） 图解： P：生产者，发送消息的程序 C：消费者：消息的接受者，会一直等待消息的到来 queue：消息队列，红色部分，缓存消息；生产者生产消息，消费者消费消息 4.3.1生产者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package cn.this52.helloworld.provide;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.ConnectionFactory;import org.junit.jupiter.api.Test;import java.io.IOException;import java.util.concurrent.TimeoutException;public class Provide &#123; @Test public void SendMessage() throws IOException, TimeoutException &#123; // 创建连接mq的连接工程对象 ConnectionFactory connectionFactory = new ConnectionFactory(); // 设置主机 connectionFactory.setHost(&quot;192.168.45.121&quot;); // 设置端口号 connectionFactory.setPort(5672); // 设置连接的虚拟主机 connectionFactory.setVirtualHost(&quot;/ems&quot;); // 设置访问虚拟主机的用户名密码 connectionFactory.setUsername(&quot;zs&quot;); connectionFactory.setPassword(&quot;123&quot;); // 获取连接对象 Connection connection = connectionFactory.newConnection(); // 获取连接通道 Channel channel = connection.createChannel(); /* * 声明消息队列 * 参数1：队列名称（不存在时会自动创建） * 参数2：用来定义队列特性是否要持久化 * 参数3：是否独占队列 * 参数4：是否在消费完成后自动删除队列 * 参数5：额外附加参数 * */ channel.queueDeclare(&quot;hello&quot;,false,false,false,null); /* * 发布消息 * 参数1：交换机名 * 参数2： * 参数3：额外属性 * 参数4：消息内容 * */ channel.basicPublish(&quot;&quot;,&quot;hello&quot;,null,&quot;hello rabbitmq&quot;.getBytes()); channel.close(); connection.close(); &#125; &#125; 4.3.2消费者1234567891011121314151617181920212223242526272829303132333435363738394041package cn.this52.helloworld;import com.rabbitmq.client.*;import java.io.IOException;import java.util.concurrent.TimeoutException;public class Consumer &#123; public static void main(String[] args) throws IOException, TimeoutException, InterruptedException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost(&quot;192.168.45.121&quot;); connectionFactory.setPort(5672); connectionFactory.setVirtualHost(&quot;/ems&quot;); connectionFactory.setUsername(&quot;zs&quot;); connectionFactory.setPassword(&quot;123&quot;); Connection connection = connectionFactory.newConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(&quot;hello&quot;, false, false, false, null); DefaultConsumer consumer = new DefaultConsumer(channel) &#123; /** * * @param consumerTag 标识 * @param envelope 获取信息（交换机、路由key等等） * @param properties 配置信息 * @param body 消息数据 * @throws IOException io */ @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;body = &quot; + new String(body)); &#125; &#125;; // 消费消息 channel.basicConsume(&quot;hello&quot;, true, consumer); // 不关闭连接 &#125;&#125; 注意： 单元测试环境中不支持多线程，无法测试消费 4.3.3API细节1234567891011121314151617181920/* * 声明消息队列 * 参数1：队列名称（不存在时会自动创建） * 参数2：用来定义队列特性是否要持久化(只会持久化队列，不会持久化消息) * 参数3：是否独占队列(一般都不会独占) * 参数4：是否在消费完成后自动删除队列(队列没有被占用时) * 参数5：额外附加参数 * */channel.queueDeclare(&quot;hello&quot;,true,false,false,null);/* * 发布消息 * 参数1：交换机名 * 参数2：路由key * 参数3：额外属性 设置为MessageProperties.PERSISTENT_TEXT_PLAIN会持久化消息 * 参数4：消息内容 * */channel.basicPublish(&quot;&quot;,&quot;hello&quot;, MessageProperties.PERSISTENT_TEXT_PLAIN,&quot;hello rabbitmq&quot;.getBytes()); 生产者和消费者通道参数要一致！ 4.4第二种模型（work queue）Work Queues也被称为Task queus，任务模型，当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度，长时间的话消息会堆积的越来越多，无法及时处理，此时可以用work模型：让多个消费者绑定到一个队列，共同消费队列中的消息。队列中的消息一旦被消费就会消失，不会重复消费。 图解： P：生产者：任务发布者 C1：消费者1，消费任务 C2：消费者2，消费任务 4.4.1生产者12345678910111213141516171819202122package cn.this52.helloworld.work;import cn.this52.RabbitMQUtils;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import com.rabbitmq.client.MessageProperties;import java.io.IOException;public class Provider &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitMQUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(&quot;work&quot;, true, false, false, null); for (int i = 0; i &lt; 10; i++) &#123; channel.basicPublish(&quot;&quot;, &quot;work&quot;, MessageProperties.PERSISTENT_TEXT_PLAIN, (&quot;hello work queues&quot;+i).getBytes()); &#125; RabbitMQUtils.close(connection, channel); &#125;&#125; 4.4.2消费者112345678910111213141516171819202122package cn.this52.helloworld.work;import cn.this52.RabbitMQUtils;import com.rabbitmq.client.*;import java.io.IOException;public class Consumer1 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitMQUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(&quot;work&quot;, true, false, false, null); channel.basicConsume(&quot;work&quot;, true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者1：&quot;+new String(body)); &#125; &#125;); &#125;&#125; 4.4.3消费者212345678910111213141516171819202122package cn.this52.helloworld.work;import cn.this52.RabbitMQUtils;import com.rabbitmq.client.*;import java.io.IOException;public class Consumer2 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitMQUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(&quot;work&quot;, true, false, false, null); channel.basicConsume(&quot;work&quot;, true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;消费者2：&quot;+new String(body)); &#125; &#125;); &#125;&#125; 4.4.4测试 默认情况下，RabbitMQ将按顺序将每个消息发送给下一个使用者。平均而言，每个消费者都会收到相同数量的消息。这种分发消息的方式称为循环 4.4.5消息确认机制 自动确认消息可能会造成消息丢失，所以需要 12345678910111213// 一次消费一条消息 channel.basicQos(1); // 参数2：autoAck 是否自动向rabbitmq确认消息被消费 channel.basicConsume(&quot;work&quot;, false, new DefaultConsumer(channel) &#123; @SneakyThrows @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; Thread.sleep(2000); System.out.println(&quot;消费者2：&quot; + new String(body)); // 参数1：消息标识 参数2：是否确认多个消息 channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125;); 设置通道一次消费一条消息 关闭消息消费自动确认，开启手动确认 4.5第三种模型（发布订阅-&gt;fanout）广播 在广播模式下，消息发送流程： 可以有多个消费者 每个消费者都有自己的queue(队列) 每个队列都要绑定到Exchange（交换机） 生产者发送的消息，只能发送到交换机，交换机来决定发送给那个队列，生产者无法决定 交换机把消息发送给绑定过的所有队列 队列的消费者都能拿到消息，实现一条消息被多个消费者消费 4.5.1生产者123456789101112131415161718192021package cn.this52.helloworld.fanout;import cn.this52.RabbitMQUtils;import com.rabbitmq.client.Channel;import com.rabbitmq.client.Connection;import java.io.IOException;public class Provider &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitMQUtils.getConnection(); Channel channel = connection.createChannel(); // 声明交换机 参数1：交换机名 参数2：交换机类型 fanout：广播类型 channel.exchangeDeclare(&quot;order&quot;, &quot;fanout&quot;); channel.basicPublish(&quot;order&quot;,&quot;&quot;,null,&quot;fanout type message&quot;.getBytes()); RabbitMQUtils.close(connection,channel); &#125;&#125; 4.5.2消费者(3)1234567891011121314151617181920212223242526package cn.this52.helloworld.fanout;import cn.this52.RabbitMQUtils;import com.rabbitmq.client.*;import java.io.IOException;public class Consumer1 &#123; public static void main(String[] args) throws IOException &#123; Connection connection = RabbitMQUtils.getConnection(); Channel channel = connection.createChannel(); // 声明交换机 channel.exchangeDeclare(&quot;order&quot;, &quot;fanout&quot;); // 临时队列 String queue = channel.queueDeclare().getQueue(); // 绑定交换机和队列 channel.queueBind(queue, &quot;order&quot;, &quot;&quot;); channel.basicConsume(queue, true, new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) &#123; System.out.println(&quot;消费者1：&quot;+new String(body)); &#125; &#125;); &#125;&#125; 遇到一个错误 17行是channel.queueBind不是channel.exchangeBind 4.5.3测试结果 绑定交换机的队列都会收到消息，消费者也都消费到了同样的消息 4.6第四种模型（Routing之订阅模型-Direct）在fanout模式中，一条消息，会被所有订阅的队列都消费。但是某些情况下我们希望不同的消息被不同的队列所消费，这时候就要用到Direct类型的Exchange。 在Driect模型下： 队列和交换机的绑定，要指定一个RoutingKey 消息的生产者在向交换机发送消息时，必须指定RoutingKey 交换机不再把消息发给每一个绑定的队列，而是根据消息的RoutingKey进行判断，只有队列的RoutingKey与消息的的RoutingKey完全一致，才能接受到消息。 图解： P：生产者，向交换机发送消息，并指定RoutingKey X：交换机，接收生产者的消息，然后把消息递交给与RoutingKey匹配的队列 C1：消费者，其所在队列指定了需要RoutignKey为error的消息 C2：消费者，其所在队列指定了需要RoutignKey为info、error、warning的消息 4.6.1生产者123456// 声明交换机 类型为directchannel.exchangeDeclare(&quot;order_direct&quot;, &quot;direct&quot;);String routingKey=&quot;info&quot;;// 声明RoutingKeychannel.basicPublish(&quot;order_direct&quot;, routingKey, null, (&quot;基于direct的消息-&gt;&quot;+routingKey).getBytes()); 4.6.2消费者112345channel.exchangeDeclare(&quot;order_direct&quot;,&quot;direct&quot;);String queue = channel.queueDeclare().getQueue();// 绑定队列以及RoutingKeychannel.queueBind(queue,&quot;order_direct&quot;,&quot;error&quot;); 4.6.3消费者21234567channel.exchangeDeclare(&quot;order_direct&quot;,&quot;direct&quot;);String queue = channel.queueDeclare().getQueue();// 绑定队列以及RoutingKeychannel.queueBind(queue,&quot;order_direct&quot;,&quot;error&quot;);channel.queueBind(queue,&quot;order_direct&quot;,&quot;info&quot;);channel.queueBind(queue,&quot;order_direct&quot;,&quot;warning&quot;); 测试routingkey=info 消费者1未收到消息 测试routingkey=error 4.7第五种消息模型（Routing之订阅模型-Topics）与Direct模型相比，都是可以根据RoutingKey把消息路由到不同的队列，只不过Topic类型交换机可以让队列在绑定RoutingKey时使用通配符。这种模型RoutingKey一般都是由一个或者多个单词组成，多个单词之间以’’.’’分隔 图解： P：生产者，向交换机发送消息，并指定RoutingKey X：交换机，类型为topic，接收生产者的消息，然后把消息递交给与RoutingKey匹配的队列 Q1：队列1，只接收routingKey为*.orange. *的消息 Q2：对列2，接收routingKey为*. *.rabbit和lazy.#的消息 C1：消费者1，消费队列中的消息 C2：消费者2 123456# 通配符*（星号）可以代替一个单词。＃（哈希）可以替代零个或多个单词。auto.# 匹配auto.a或者auto.a.bauto.* 只能匹配auto.a 或者auto.b 4.7.1生产者1234// 声明交换机及类型 topicchannel.exchangeDeclare(&quot;log_topic&quot;, &quot;topic&quot;);String routingKey = &quot;user.add.aa&quot;;channel.basicPublish(&quot;log_topic&quot;, routingKey, null, (&quot;基于topic的消息,routingKey：&quot; + routingKey).getBytes()); 4.7.2消费者1123channel.exchangeDeclare(&quot;log_topic&quot;, &quot;topic&quot;);String queue = channel.queueDeclare().getQueue();channel.queueBind(queue, &quot;log_topic&quot;, &quot;user.*&quot;); 4.7.3消费者2123channel.exchangeDeclare(&quot;log_topic&quot;, &quot;topic&quot;);String queue = channel.queueDeclare().getQueue();channel.queueBind(queue, &quot;log_topic&quot;, &quot;user.#&quot;); 4.7.4测试user.add和user.add.aa 5.SpringBoot整合RabbitMQ5.1环境5.1.1引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 5.1.2配置文件123456789spring: application: name: rabbitmq-springboot rabbitmq: host: 192.168.45.126 port: 5672 virtual-host: /ems username: ems password: 123 5.2hello world模型使用123456789// 监听Rabbit 声明队列 默认持久化非独占不自动删除@RabbitListener(queuesToDeclare = @Queue(value = &quot;hello&quot;,autoDelete = &quot;true&quot;))@Component // 需要注册到Spring容器中public class HelloConsumer &#123; @RabbitHandler public void test(String message) &#123; System.out.println(&quot;message = &quot; + message); &#125;&#125; 12345678910111213@SpringBootTestclass RabbitmqHelloworldApplicationTests &#123; // 注入rabbitTemplate @Autowired private RabbitTemplate rabbitTemplate; @Test void contextLoads() &#123; rabbitTemplate.convertAndSend(&quot;hello&quot;,&quot;hello world rabbitmq-springboot&quot;); &#125;&#125; 5.3work模型123456@Testpublic void work() &#123; for (int i = 0; i &lt; 10; i++) &#123; rabbitTemplate.convertAndSend(&quot;work&quot;, &quot;work模型&quot; + i); &#125;&#125; 123456789101112131415@Componentpublic class WorkConsumer &#123; @RabbitListener(queuesToDeclare = @Queue(&quot;work&quot;)) @RabbitHandler public void consumer1(String message)&#123; System.out.println(&quot;consumer1 = &quot; + message); &#125; @RabbitListener(queuesToDeclare = @Queue(&quot;work&quot;)) @RabbitHandler public void consumer2(String message)&#123; System.out.println(&quot;consumer2 = &quot; + message); &#125;&#125; 默认是公平分配的，需要能者多劳的话得额外配置 5.4fanout模型1234@Testvoid fanout() &#123; rabbitTemplate.convertAndSend(&quot;fanout_logs&quot;, &quot;&quot;, &quot;fanout模型&quot;);&#125; 1234567891011121314151617181920212223242526@Componentpublic class FanoutConsumer &#123; @RabbitListener(bindings = @QueueBinding( value = @Queue, //临时队列 exchange = @Exchange(value = &quot;fanout_logs&quot;,type = &quot;fanout&quot;) // 默认direct )) public void consumer1(String message) &#123; System.out.println(&quot;consumer1 = &quot; + message); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue, //临时队列 exchange = @Exchange(value = &quot;fanout_logs&quot;,type = &quot;fanout&quot;) )) public void consumer2(String message) &#123; System.out.println(&quot;consumer2 = &quot; + message); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue, //临时队列 exchange = @Exchange(value = &quot;fanout_logs&quot;,type = &quot;fanout&quot;) )) public void consumer3(String message) &#123; System.out.println(&quot;consumer3 = &quot; + message); &#125;&#125; 5.5Direct模型12345@Testvoid routingKey() &#123; String routingKey = &quot;error&quot;; rabbitTemplate.convertAndSend(&quot;routing_logs&quot;, routingKey, routingKey + &quot;信息&quot;);&#125; 1234567891011121314151617181920@Componentpublic class RoutingKey &#123; @RabbitListener(bindings = @QueueBinding( value = @Queue, exchange = @Exchange(value = &quot;routing_logs&quot;), key = &quot;info&quot; )) public void consumer1(String message)&#123; System.out.println(&quot;consumer1 = &quot; + message); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue, exchange = @Exchange(&quot;routing_logs&quot;), //默认交换机类型为direct，所以无需设置 key = &#123;&quot;error&quot;,&quot;warning&quot;,&quot;info&quot;&#125; )) public void consumer2(String message)&#123; System.out.println(&quot;consumer2 = &quot; + message); &#125;&#125; 5.6Topics模型12345@Testvoid topics() &#123; String routingKey = &quot;user.save.a&quot;; rabbitTemplate.convertAndSend(&quot;topics_logs&quot;, routingKey, routingKey + &quot;信息&quot;);&#125; 12345678910111213141516171819202122@Componentpublic class TopicsConsumer &#123; @RabbitListener(bindings = @QueueBinding( value = @Queue, exchange = @Exchange(value = &quot;topics_logs&quot;,type = &quot;topic&quot;), key = &#123;&quot;user.*&quot;&#125; )) public void consumer1(String message)&#123; System.out.println(&quot;consumer1 = &quot; + message); &#125; @RabbitListener(bindings = @QueueBinding( value = @Queue, exchange = @Exchange(value = &quot;topics_logs&quot;,type = &quot;topic&quot;), key = &#123;&quot;user.#&quot;&#125; )) public void consumer2(String message)&#123; System.out.println(&quot;consumer2 = &quot; + message); &#125;&#125; 1@RabbitListener标注在方法上时可以不用加@RabbitHandler注解 消息手动确认 12345678listener: # 设置模式为手动 direct: acknowledge-mode: manual simple: acknowledge-mode: manual # 消费信息数 concurrency: 1 12345678@SneakyThrows@RabbitListener(queuesToDeclare = @Queue(&quot;work&quot;))public void consumer1(String content, Message message, Channel channel)&#123; System.out.println(&quot;content = &quot; + content); // 确认消息 不同时确认多个 channel.basicAck(message.getMessageProperties().getDeliveryTag(),false);&#125; 6.应用场景异步处理 应用解耦 流量削峰 7.RabbitMQ集群7.1集群架构7.1.1副本集群","categories":[{"name":"MQ","slug":"MQ","permalink":"https://blog.this52.cn/categories/MQ/"}],"tags":[{"name":"MQ","slug":"MQ","permalink":"https://blog.this52.cn/tags/MQ/"},{"name":"RabiitMQ","slug":"RabiitMQ","permalink":"https://blog.this52.cn/tags/RabiitMQ/"}]},{"title":"Redis随记","slug":"Redis","date":"2020-07-26T16:00:00.000Z","updated":"2020-09-19T16:00:00.000Z","comments":true,"path":"posts/2ce3cbd6/","link":"","permalink":"https://blog.this52.cn/posts/2ce3cbd6/","excerpt":"","text":"NoSql概述什么是NoSqlNoSql=Not Only SQL,不仅仅是SQL 泛指非关系型数据库 NOSQL特点 方便扩展（数据之间没有好关系） 大数据量高性能（Redis一秒写入8万次，读取11万次） 数据类型是多样型的 NoSQL四大分类K-V键值对： Redis memacache 文档型数据库： MongoDB 列存储数据库： 图关系数据库： Redis入门redis安装1.下载redis-5.0.9.tar.gz 2.解压 1tar -zxvf redis-5.0.9.tar.gz 3.进入解压后的文件夹,可以看到redis配置文件 4.基本环境安装 12# 要在redis目录执行make &amp;&amp; make install 没有error就是成功了 5.redis默认安装路径/usr/local/bin 6.复制一个配置文件 7.修改配置文件,136行左右,设置为后台启动（守护线程） 8.启动redis服务,通过指定的配置文件启动服务 9.使用redis-cli进行连接测试 10.查看redis进程 1ps -ef |grep redis 11.关闭redis服务 redis-benchmark性能测试redis 性能测试的基本命令如下： 1redis-benchmark [option] [option value] redis 性能测试工具可选参数如下所示： 序号 选项 描述 默认值 1 -h 指定服务器主机名 127.0.0.1 2 -p 指定服务器端口 6379 3 -s 指定服务器 socket 4 -c 指定并发连接数 50 5 -n 指定请求数 10000 6 -d 以字节的形式指定 SET/GET 值的数据大小 2 7 -k 1=keep alive 0=reconnect 1 8 -r SET/GET/INCR 使用随机 key, SADD 使用随机值 9 -P 通过管道传输 请求 1 10 -q 强制退出 redis。仅显示 query/sec 值 11 –csv 以 CSV 格式输出 12 -l 生成循环，永久执行测试 13 -t 仅运行以逗号分隔的测试命令列表。 14 -I Idle 模式。仅打开 N 个 idle 连接并等待。 12#测试100个并发连接,10万次请求redis-benchmark -h localhost -p 6379 -c 100 -n 100000 Redis数据类型 用作数据库、缓存、消息中间件 Reids Keys123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:6379&gt; keys * # 查看所有key(empty list or set)127.0.0.1:6379&gt; set name aurora # 设置一个keyOK127.0.0.1:6379&gt; keys *1) &quot;name&quot;127.0.0.1:6379&gt; exists name # 查看key是否存在(integer) 1127.0.0.1:6379&gt; exists name1(integer) 0127.0.0.1:6379&gt; move name 1 # 移动一个key到指定数据库(integer) 1127.0.0.1:6379&gt; keys *(empty list or set)127.0.0.1:6379&gt; set age 1OK127.0.0.1:6379&gt; keys *1) &quot;age&quot;127.0.0.1:6379&gt; set name auroraOK127.0.0.1:6379&gt; clear127.0.0.1:6379&gt;127.0.0.1:6379&gt; keys *1) &quot;name&quot;2) &quot;age&quot;127.0.0.1:6379&gt; get name&quot;aurora&quot;127.0.0.1:6379&gt; EXPIRE name 10 # 设置过期时间 10s(integer) 1127.0.0.1:6379&gt; keys *1) &quot;name&quot;2) &quot;age&quot;127.0.0.1:6379&gt; ttl name # 检查剩余生存时间(integer) 1127.0.0.1:6379&gt; ttl name(integer) -2127.0.0.1:6379&gt; get name(nil)127.0.0.1:6379&gt; type age # 查看key类型string127.0.0.1:6379&gt; Strings（字符串）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160127.0.0.1:6379&gt; set key1 v1 # 设置一个值OK127.0.0.1:6379&gt; get key1 # 取值&quot;v1&quot;127.0.0.1:6379&gt; EXISTS key1 # 查看key是否存在(integer) 1127.0.0.1:6379&gt; APPEND key1 hello # 追加字符串，如果当前key不存在，相当于直接设置一个key(integer) 7127.0.0.1:6379&gt; get key1&quot;v1hello&quot;127.0.0.1:6379&gt; STRLEN key1 # 查看字符串长度(integer) 7127.0.0.1:6379&gt; APPEND key1 111111111(integer) 16127.0.0.1:6379&gt; STRLEN key1(integer) 16127.0.0.1:6379&gt;127.0.0.1:6379&gt; APPEND name aurora(integer) 6127.0.0.1:6379&gt; keys *1) &quot;name&quot;2) &quot;key1&quot;3) &quot;age&quot;127.0.0.1:6379&gt;###################################################++和--操作127.0.0.1:6379&gt; set views 0 # 设置一个值OK127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt; INCR views # 加1操作(integer) 1127.0.0.1:6379&gt; get views&quot;1&quot;127.0.0.1:6379&gt; INCR views(integer) 2127.0.0.1:6379&gt; INCR views(integer) 3127.0.0.1:6379&gt; get views&quot;3&quot;127.0.0.1:6379&gt; DECR views # 减1操作(integer) 2127.0.0.1:6379&gt; DECR views(integer) 1127.0.0.1:6379&gt; get views&quot;1&quot;127.0.0.1:6379&gt;###############步长127.0.0.1:6379&gt; INCRBY views 10 # 加10(integer) 11127.0.0.1:6379&gt; get viw(nil)127.0.0.1:6379&gt; get views&quot;11&quot;127.0.0.1:6379&gt; DECRBY views 11 # 减11(integer) 0127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt;#################################################### 字符串范围 range127.0.0.1:6379&gt; set key1 hello,world # 设置一个字符串OK127.0.0.1:6379&gt; get key1&quot;hello,world&quot;127.0.0.1:6379&gt; GETRANGE key1 0 3 # 截取字符串【0,3】&quot;hell&quot;127.0.0.1:6379&gt; GETRANGE key1 0 -1 # 截取全部字符串&quot;hello,world&quot;127.0.0.1:6379&gt;127.0.0.1:6379&gt; set key2 abcdefgOK127.0.0.1:6379&gt; SETRANGE key2 1 xxx # 替换指定位置字符串(integer) 7127.0.0.1:6379&gt; get key2&quot;axxxefg&quot;127.0.0.1:6379&gt;###################################################setex # 设置过期时间setnx # 如果当前值不存在才设置127.0.0.1:6379&gt; SETEX key3 30 helloclear # 设置key3过期时间为30sOK127.0.0.1:6379&gt; ttl key3(integer) 26127.0.0.1:6379&gt; ttl key3(integer) 24127.0.0.1:6379&gt; ttl key3(integer) 23127.0.0.1:6379&gt; ttl key3(integer) -2127.0.0.1:6379&gt;127.0.0.1:6379&gt; SETNX key4 redis # 创建key4成功(integer) 1127.0.0.1:6379&gt; keys *1) &quot;key4&quot;2) &quot;key2&quot;3) &quot;key1&quot;127.0.0.1:6379&gt; SETNX key4 redis22222 # key4存在，创建不成功(integer) 0127.0.0.1:6379&gt; get key4&quot;redis&quot;127.0.0.1:6379&gt;###################################################msetmget127.0.0.1:6379&gt; mset k1 v1 k2 v2 k3 v3 # 设置多个keyOK127.0.0.1:6379&gt; keys *1) &quot;k3&quot;2) &quot;k2&quot;3) &quot;k1&quot;127.0.0.1:6379&gt; mget k1 k2 # 获取多个key1) &quot;v1&quot;2) &quot;v2&quot;127.0.0.1:6379&gt; MSETNX k1 v1 k4 v4 # 如果key不存在，设置多个key，如果有一个key存在，都会失败（原子性操作）(integer) 0127.0.0.1:6379&gt; keys *1) &quot;k3&quot;2) &quot;k2&quot;3) &quot;k1&quot;127.0.0.1:6379&gt;对象################################################set user:1 &#123;name:zhangsan,age:3&#125; #设置user:1对象,值为json字符串来保存127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 18OK127.0.0.1:6379&gt; mget user:1:name user:1:age1) &quot;zhangsan&quot;2) &quot;18&quot;127.0.0.1:6379&gt;###################################################getset # 先get再set127.0.0.1:6379&gt; getset db redis # 获取值再设置值，如果不存在返回nil(nil)127.0.0.1:6379&gt; get db&quot;redis&quot;127.0.0.1:6379&gt; getset db mysql # 获取值再设置值，如果存在，返回原来的值，然后设置新的值&quot;redis&quot;127.0.0.1:6379&gt; get db&quot;mysql&quot;127.0.0.1:6379&gt;################################################### Lists（列表）按插入顺序排序的字符串元素的集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181###################################################LPUSH RPUSHLRANGE127.0.0.1:6379&gt; LPUSH list one # 将一个或多个值插入到列表头部(integer) 1127.0.0.1:6379&gt; LPUSH list two(integer) 2127.0.0.1:6379&gt; LPUSH list three(integer) 3127.0.0.1:6379&gt; LRANGE list 0 -1 # 获取列表所有值1) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; LRANGE list 0 1 # 获取列表指定值【0,1】1) &quot;three&quot;2) &quot;two&quot;# 因为LPUSH是往头部插入的，所以才会是这个顺序127.0.0.1:6379&gt; RPUSH list four(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -1 # 将一个或多个值插入到列表尾部1) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;four&quot;###################################################LPOPRPOP127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;four&quot;127.0.0.1:6379&gt; LPOP list # 移除list的第一个值&quot;three&quot;127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;3) &quot;four&quot;127.0.0.1:6379&gt; RPOP list # 移除list的最后一个值&quot;four&quot;127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;127.0.0.1:6379&gt;###################################################LINDEX127.0.0.1:6379&gt; LINDEX list 0 # 第1个值&quot;two&quot;127.0.0.1:6379&gt; LINDEX list 1 # 第2个值&quot;one&quot;127.0.0.1:6379&gt;###################################################LLEN127.0.0.1:6379&gt; flushdb # 清空数据库OK127.0.0.1:6379&gt; LPUSH list one(integer) 1127.0.0.1:6379&gt; LPUSH list one2(integer) 2127.0.0.1:6379&gt; LPUSH list one3(integer) 3127.0.0.1:6379&gt; LLEN list # 获取列表长度(integer) 3127.0.0.1:6379&gt;###################################################LREM127.0.0.1:6379&gt; LPUSH list one(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -1 # 可以发现value是可以重复的1) &quot;one&quot;2) &quot;one3&quot;3) &quot;one2&quot;4) &quot;one&quot;127.0.0.1:6379&gt; LREM list 1 one2 # 移除指定个数的value(integer) 1127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;one&quot;2) &quot;one3&quot;3) &quot;one&quot;127.0.0.1:6379&gt; LREM list 2 one # 移除两个值(integer) 2127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;one3&quot;127.0.0.1:6379&gt;###################################################LTRIM127.0.0.1:6379&gt; LPUSH mylist hello2(integer) 3127.0.0.1:6379&gt; LPUSH mylist hello3(integer) 4127.0.0.1:6379&gt; LPUSH mylist hello4(integer) 5127.0.0.1:6379&gt; LPUSH mylist hello5 hello6(integer) 7127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello6&quot;2) &quot;hello5&quot;3) &quot;hello4&quot;4) &quot;hello3&quot;5) &quot;hello2&quot;6) &quot;hello1&quot;7) &quot;hello&quot;127.0.0.1:6379&gt; LTRIM mylist 1 2 # 截取列表，通过下标[1,2]，列表会被改变。（在这里LPUSH和RPUSH后的结果有区别的）OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello5&quot;2) &quot;hello4&quot;###################################################RPOPLPUSH127.0.0.1:6379&gt; FLUSHALLOK127.0.0.1:6379&gt; clear127.0.0.1:6379&gt; LPUSH mysqlist hello hello1 hello2(integer) 3127.0.0.1:6379&gt; LRANGE mylist 0 -1(empty list or set)127.0.0.1:6379&gt; LRANGE mysqlist 0 -11) &quot;hello2&quot;2) &quot;hello1&quot;3) &quot;hello&quot;127.0.0.1:6379&gt; RPOPLPUSH mysqlist otherlist # 移除列表的最后一个元素到新的列表&quot;hello&quot;127.0.0.1:6379&gt; LRANGE mysqlist 0 -11) &quot;hello2&quot;2) &quot;hello1&quot;127.0.0.1:6379&gt; LRANGE otherlist 0 -11) &quot;hello&quot;###################################################LSET127.0.0.1:6379&gt; FLUSHALLOK127.0.0.1:6379&gt; clear127.0.0.1:6379&gt; EXISTS list # 判断列表是否存在(integer) 0127.0.0.1:6379&gt; LSET list 0 aa # 列表不存在时不能set(error) ERR no such key127.0.0.1:6379&gt; LPUSH list bb(integer) 1127.0.0.1:6379&gt; LSET list 0 aa # 列表存在时会覆盖整个值OK127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;aa&quot;127.0.0.1:6379&gt; LSET list 1 aa # 指定下标值不存在时不能set(error) ERR index out of range127.0.0.1:6379&gt;###################################################LINSERT127.0.0.1:6379&gt; LPUSH list hello word(integer) 2127.0.0.1:6379&gt; LINSERT list before word , # 往列表指定元素前面插入一个元素(integer) 3127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;,&quot;2) &quot;word&quot;3) &quot;hello&quot;127.0.0.1:6379&gt; LINSERT list after word new # 往列表指定元素后面插入一个元素(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;,&quot;2) &quot;word&quot;3) &quot;new&quot;4) &quot;hello&quot;127.0.0.1:6379&gt;################################################### Lists实际上是一个链表，基于Linked LIsts实现，所以插效率非常高，但是访问效率并不是特别高，快速访问集合后面会有sorted sets key会自动创建，在插入元素时key不存在会自动创建空list，当我们移除元素时，如果值是空的，key会被自动销毁 Sets（集合）不重复且无序的字符串元素的集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139127.0.0.1:6379&gt; sadd myset &quot;hello&quot; # 添加一个元素(integer) 1127.0.0.1:6379&gt; sadd myset &quot;1111&quot; (integer) 1127.0.0.1:6379&gt; sadd myset &quot;aurora&quot;(integer) 1127.0.0.1:6379&gt; SMEMBERS myset # 查看所有元素1) &quot;1111&quot;2) &quot;hello&quot;3) &quot;aurora&quot;127.0.0.1:6379&gt; SMEMBERS myset1) &quot;1111&quot;2) &quot;hello&quot;3) &quot;aurora&quot; 127.0.0.1:6379&gt; SISMEMBER myset hello # 查看指定元素是否存在于set集合中(integer) 1127.0.0.1:6379&gt; SISMEMBER myset h(integer) 0###################################################SCARD127.0.0.1:6379&gt; SADD myset hello(integer) 1127.0.0.1:6379&gt; SADD myset hello1(integer) 1127.0.0.1:6379&gt; SADD myset hello2(integer) 1127.0.0.1:6379&gt; SADD myset hello # 重复就不能添加了(integer) 0127.0.0.1:6379&gt; SCARD myset # 查看集合中元素的个数(integer) 3127.0.0.1:6379&gt;###################################################SREM127.0.0.1:6379&gt; SREM myset hello # 移除一个元素(integer) 1127.0.0.1:6379&gt; SCARD myset(integer) 2127.0.0.1:6379&gt; SMEMBERS myset1) &quot;hello1&quot;2) &quot;hello2&quot;127.0.0.1:6379&gt;###################################################SRANDMEMBER127.0.0.1:6379&gt; SRANDMEMBER myset # 随机抽选一个元素&quot;hello2&quot;(1.52s)127.0.0.1:6379&gt; SRANDMEMBER myset&quot;hello1&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;hello2&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;hello1&quot;127.0.0.1:6379&gt; SRANDMEMBER myset 2 # 随机抽选指定个数的元素1) &quot;hello1&quot;2) &quot;hello2&quot;###################################################SPOP127.0.0.1:6379&gt; SADD myset he(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;hello1&quot;2) &quot;he&quot;3) &quot;hello2&quot;127.0.0.1:6379&gt; SPOP myset # 随机删除一个元素&quot;he&quot;127.0.0.1:6379&gt; SMEMBERS myset1) &quot;hello1&quot;2) &quot;hello2&quot;###################################################SMOVE127.0.0.1:6379&gt; SADD myset hello(integer) 1127.0.0.1:6379&gt; SADD myset world(integer) 1127.0.0.1:6379&gt; SADD myset 22(integer) 1127.0.0.1:6379&gt; SADD myset2 nihao(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;hello&quot;2) &quot;22&quot;3) &quot;world&quot;127.0.0.1:6379&gt; SMEMBERS myset21) &quot;nihao&quot;127.0.0.1:6379&gt; SMOVE myset myset2 22 # 将一个指定的值移动到目标集合(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; SMEMBERS myset21) &quot;22&quot;2) &quot;nihao&quot;###################################################INTER # 交集DIFF # 差集UNION # 并集127.0.0.1:6379&gt; SADD key1 a(integer) 1127.0.0.1:6379&gt; SADD key1 b(integer) 1127.0.0.1:6379&gt; SADD key1 c(integer) 1127.0.0.1:6379&gt; SADD key2 c(integer) 1127.0.0.1:6379&gt; SADD key2 d(integer) 1127.0.0.1:6379&gt; SADD key2 e(integer) 1127.0.0.1:6379&gt; SMEMBERS key11) &quot;c&quot;2) &quot;b&quot;3) &quot;a&quot;127.0.0.1:6379&gt; SMEMBERS key21) &quot;e&quot;2) &quot;d&quot;3) &quot;c&quot;127.0.0.1:6379&gt; SINTER key1 key21) &quot;c&quot;127.0.0.1:6379&gt; SDIFF key1 key21) &quot;a&quot;2) &quot;b&quot;127.0.0.1:6379&gt; SUNION key1 key21) &quot;c&quot;2) &quot;a&quot;3) &quot;b&quot;4) &quot;e&quot;5) &quot;d&quot;################################################### Hashes（哈希）Map集合 key-map 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465HSET # 设置一个hash键值对HGET # 获取一个hash里面的字段值HMSET # 设置多个hash键值对HGETALL # 获取hash里面的所有键值对127.0.0.1:6379&gt; HSET myhash k1 v1(integer) 1127.0.0.1:6379&gt; HGET myhash k1&quot;v1&quot;127.0.0.1:6379&gt; HMSET myhash k1 v1 k2 v2 k3 v3OK127.0.0.1:6379&gt; HMGET myhash k1 k2 k31) &quot;v1&quot;2) &quot;v2&quot;3) &quot;v3&quot;127.0.0.1:6379&gt; HGETALL myhash1) &quot;k1&quot;2) &quot;v1&quot;3) &quot;k2&quot;4) &quot;v2&quot;5) &quot;k3&quot;6) &quot;v3&quot;127.0.0.1:6379&gt; HDEL myhash k1 # 删除hash指定的字段(integer) 1127.0.0.1:6379&gt; HGETALL myhash1) &quot;k2&quot;2) &quot;v2&quot;3) &quot;k3&quot;4) &quot;v3&quot;####################################################HLEN # 获取hash长度127.0.0.1:6379&gt; HLEN myhash(integer) 2####################################################HEXISTS127.0.0.1:6379&gt; HEXISTS myhash k1 # 查看hash的指定字段是否存在(integer) 0127.0.0.1:6379&gt; HEXISTS myhash k2(integer) 1####################################################HKEYS # 获取hash中所有字段HVALS # 获取hash中所有字段的值127.0.0.1:6379&gt; HKEYS myhash1) &quot;k2&quot;2) &quot;k3&quot;127.0.0.1:6379&gt; HVALS myhash1) &quot;v2&quot;2) &quot;v3&quot;127.0.0.1:6379&gt;####################################################HINCRBY # 增加指定哈希集合中指定字段的值127.0.0.1:6379&gt; HMSET myhash k1 5 k2 9OK127.0.0.1:6379&gt; HINCRBY myhash k1 1(integer) 6127.0.0.1:6379&gt; HINCRBY myhash k2 -1(integer) 8#################################################### Zset（有序集合）有序不重复 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960ZADD # 添加一个值ZRANGE # 查看指定范围的元素127.0.0.1:6379&gt; ZADD myset 1 one 2 two 3 three(integer) 3127.0.0.1:6379&gt; ZRANGE myset 0 -11) &quot;one&quot;2) &quot;two&quot;3) &quot;three&quot;####################################################127.0.0.1:6379&gt; zadd salar 1000 zh # 添加三个用户(integer) 1127.0.0.1:6379&gt; zadd salar 100 zh2(integer) 1127.0.0.1:6379&gt; zadd salar 10000 zh3(integer) 1127.0.0.1:6379&gt; ZRANGE salar 0 -1 # 查看所有用户（从小到大）1) &quot;zh2&quot;2) &quot;zh&quot;3) &quot;zh3&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salar -inf +inf # 查看所有用户（从大到小）1) &quot;zh2&quot;2) &quot;zh&quot;3) &quot;zh3&quot;127.0.0.1:6379&gt; ZREVRANGE salar 0 -1 # 查看所有用户（从小到大）1) &quot;zh3&quot;2) &quot;zh2&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salar -inf +inf withscores # 查看所有用户并带成绩1) &quot;zh2&quot;2) &quot;100&quot;3) &quot;zh&quot;4) &quot;1000&quot;5) &quot;zh3&quot;6) &quot;10000&quot;####################################################ZREM # 删除元素ZCARD # 查看集合元素个数127.0.0.1:6379&gt; ZREM salar zh(integer) 1127.0.0.1:6379&gt; ZRANGE salar 0 -11) &quot;zh2&quot;2) &quot;zh3&quot;127.0.0.1:6379&gt; ZCARD salar(integer) 2####################################################ZCOUNT # 获取指定区间的元素数量127.0.0.1:6379&gt; ZADD myset 1 h 2 j 3 k(integer) 3127.0.0.1:6379&gt; ZCOUNT myset 1 2(integer) 2127.0.0.1:6379&gt; ZCOUNT myset 1 3(integer) 3################################################### Geospatial（地理位置）Redis在3.2推出了deospatial，这个功能可以推算出地理位置的信息，两地之间的距离 GEOADD 12345678# 添加地理位置到指定key中（东经，北纬，名称），可以添加单个或多个# 有效的经度从-180度到180度。# 有效的纬度从-85.05112878度到85.05112878度。127.0.0.1:6379&gt; GEOADD china:city 114.279 30.573 wuhan 115.073 31.234 macheng 121.4445 31.213 shanghai(integer) 3127.0.0.1:6379&gt; GEOADD china:city 113.265 23.108 guangzhou 114.109 22.544 shenzhen 116.408 39.904 beijing(integer) 3 GEOPOS 123456789101112131415161718# 从指定key中返回所给位置元素的位置（东经北纬）127.0.0.1:6379&gt; GEOPOS china:city wuhan1) 1) &quot;114.27899926900863647&quot; 2) &quot;30.57299931525717795&quot;127.0.0.1:6379&gt; GEOPOS china:city wuhan macheng baijing1) 1) &quot;114.27899926900863647&quot; 2) &quot;30.57299931525717795&quot;2) 1) &quot;115.07299751043319702&quot; 2) &quot;31.23399882974727149&quot;3) (nil)127.0.0.1:6379&gt; GEOPOS china:city wuhan macheng beijing1) 1) &quot;114.27899926900863647&quot; 2) &quot;30.57299931525717795&quot;2) 1) &quot;115.07299751043319702&quot; 2) &quot;31.23399882974727149&quot;3) 1) &quot;116.40800267457962036&quot; 2) &quot;39.90399988166036138&quot; GEODIST 1234567891011121314151617181920# 返回两个位置之间的距离，如果有一个不存在返回空# 可选参数unit必须是m、km、mi、ft，默认m127.0.0.1:6379&gt; GEODIST china:city wuhan macheng&quot;105579.8472&quot;127.0.0.1:6379&gt; GEODIST china:city wuhan macheng m&quot;105579.8472&quot;127.0.0.1:6379&gt; GEODIST china:city wuhan macheng km&quot;105.5798&quot;127.0.0.1:6379&gt; GEODIST china:city macheng shanghai&quot;605948.1978&quot;127.0.0.1:6379&gt; GEODIST china:city macheng shanghai km&quot;605.9482&quot;127.0.0.1:6379&gt; GEODIST china:city macheng shanghai mi&quot;376.5197&quot;127.0.0.1:6379&gt; GEODIST china:city macheng shanghai ft&quot;1988019.0215&quot;127.0.0.1:6379&gt; GEODIST china:city macheng shangh(nil) GEORADIUS 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# 以给定的经纬度为中心，返回包含的位置元素与中心距离不超过最大距离的所有位置元素（附近的人）## 东经110北纬30 1000km范围内127.0.0.1:6379&gt; GEORADIUS china:city 110 30 1000 km1) &quot;shenzhen&quot;2) &quot;guangzhou&quot;3) &quot;wuhan&quot;4) &quot;macheng&quot;## 东经110北纬30 500km范围内127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km1) &quot;wuhan&quot;## 东经110北纬30 800km范围内127.0.0.1:6379&gt; GEORADIUS china:city 110 30 800 km1) &quot;wuhan&quot;2) &quot;macheng&quot;## 东经110北纬30 800km范围内的城市并返回经纬度127.0.0.1:6379&gt; GEORADIUS china:city 110 30 800 km withcoord1) 1) &quot;wuhan&quot; 2) 1) &quot;114.27899926900863647&quot; 2) &quot;30.57299931525717795&quot;2) 1) &quot;macheng&quot; 2) 1) &quot;115.07299751043319702&quot; 2) &quot;31.23399882974727149&quot;## 东经110北纬30 800km范围内的城市并返回与中心的距离（km）127.0.0.1:6379&gt; GEORADIUS china:city 110 30 800 km withdist1) 1) &quot;wuhan&quot; 2) &quot;415.8636&quot;2) 1) &quot;macheng&quot; 2) &quot;504.5558&quot; ## ASC: 根据中心的位置， 按照从近到远的方式返回位置元素。（默认）## DESC: 根据中心的位置， 按照从远到近的方式返回位置元素。 127.0.0.1:6379&gt; GEORADIUS china:city 110 30 800 km ASC1) &quot;wuhan&quot;2) &quot;macheng&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 800 km DESC1) &quot;macheng&quot;2) &quot;wuhan&quot;## COUNT：取前N个127.0.0.1:6379&gt; GEORADIUS china:city 110 30 1000 km1) &quot;shenzhen&quot;2) &quot;guangzhou&quot;3) &quot;wuhan&quot;4) &quot;macheng&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 1000 km COUNT 21) &quot;wuhan&quot;2) &quot;macheng&quot;127.0.0.1:6379&gt; GEORADIUSBYMENBER 12345678# 跟GEORADIUS差不多，这个是指定一个位置元素用作查询中心127.0.0.1:6379&gt; GEORADIUSBYMEMBER china:city macheng 500 km1) &quot;wuhan&quot;2) &quot;macheng&quot;127.0.0.1:6379&gt; GEORADIUSBYMEMBER china:city macheng 800 km1) &quot;wuhan&quot;2) &quot;macheng&quot;3) &quot;shanghai&quot; GEOHASH 12345678910111213# 返回一个或多个位置元素的Geohash# 11个字符的Geohash字符串# 字符串前缀越像就越近127.0.0.1:6379&gt; GEOHASH china:city macheng wuhan1) &quot;wt9cdtcx5p0&quot;2) &quot;wt3mbmxkts0&quot;127.0.0.1:6379&gt; GEOHASH china:city macheng shanghai1) &quot;wt9cdtcx5p0&quot;2) &quot;wtw3ed1hvv0&quot;127.0.0.1:6379&gt; GEOHASH china:city wuhan shanghai1) &quot;wt3mbmxkts0&quot;2) &quot;wtw3ed1hvv0&quot; GEO底层实现原理是Zset，我们可以用Zset命令来操作geo 12345678910111213141516127.0.0.1:6379&gt; ZRANGE china:city 0 -11) &quot;shenzhen&quot;2) &quot;guangzhou&quot;3) &quot;wuhan&quot;4) &quot;macheng&quot;5) &quot;shanghai&quot;6) &quot;beijing&quot;127.0.0.1:6379&gt; ZREM china:city shenzhen(integer) 1127.0.0.1:6379&gt; ZRANGE china:city 0 -11) &quot;guangzhou&quot;2) &quot;wuhan&quot;3) &quot;macheng&quot;4) &quot;shanghai&quot;5) &quot;beijing&quot;127.0.0.1:6379&gt; Hyperloglog（基数） 基数（一个集合内不重复的元素个数） A{1,3,4,5,4,7,2} 基数=6 简介 Redis Hyperloglog 基数统计的算法，它是一种概率数据结构优点：占用的内存是固定的，最多12kb 缺点：小于1的错误率 网页的UV（一个人访问一个网站多次，还是算作一个人） 1234567891011121314151617## 第一组数据127.0.0.1:6379&gt; PFADD key1 a b c d e f g(integer) 1## 第二组数据127.0.0.1:6379&gt; PFADD key2 a b t y u(integer) 1127.0.0.1:6379&gt; PFCOUNT key1(integer) 7127.0.0.1:6379&gt; PFCOUNT key2(integer) 5# 将多个Hyperloglog合并为一个Hyperloglog。合并后的Hyperloglog基数接近于输入的多个Hyperloglog的并集127.0.0.1:6379&gt; PFMERGE key3 key1 key2OK127.0.0.1:6379&gt; PFCOUNT key3(integer) 9127.0.0.1:6379&gt; Bitmaps（位图） 位图，不是一种实际的数据结,只有0和1两个状态 123456789101112131415161718192021127.0.0.1:6379&gt; SETBIT sign 0 1(integer) 0127.0.0.1:6379&gt; SETBIT sign 1 0(integer) 0127.0.0.1:6379&gt; SETBIT sign 2 0(integer) 0127.0.0.1:6379&gt; SETBIT sign 3 0(integer) 0127.0.0.1:6379&gt; SETBIT sign 4 1(integer) 0127.0.0.1:6379&gt; SETBIT sign 5 1(integer) 0127.0.0.1:6379&gt; SETBIT sign 6 1(integer) 0127.0.0.1:6379&gt; GETBIT sign 3(integer) 0127.0.0.1:6379&gt; GETBIT sign 6(integer) 1127.0.0.1:6379&gt; BITCOUNT sign(integer) 4 Redis事务 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个原子操作，事务中的命令要么全部被执行，要么全部不执行（严格来说单个命令是原子操作，多个就不一定） 没有隔离级别的概念 开启事务后的命令不会立刻执行，会加入队列，在执行事务的时候才会执行 开启事务-&gt;入队列-&gt;执行事务 123456789101112131415161718# 开启事务127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; MSET k2 v2 k3 v3QUEUED127.0.0.1:6379&gt; MGET k2 k3QUEUED127.0.0.1:6379&gt; set k4 5QUEUED## 执行事务127.0.0.1:6379&gt; EXEC1) OK2) OK3) 1) &quot;v2&quot; 2) &quot;v3&quot;4) OK 1234567891011121314# 放弃事务 会清空队列，然后放弃事务127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; set k5 v5QUEUED127.0.0.1:6379&gt; DISCARDOK127.0.0.1:6379&gt; get v5(nil)127.0.0.1:6379&gt; keys *1) &quot;k3&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;k1&quot; 事务中的错误 在事务执行前，入队的命令可能会出错，出错后事务执行时会放弃事务 1234567891011121314127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; getset k2 # 错误的命令(error) ERR wrong number of arguments for &#x27;getset&#x27; command127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors.127.0.0.1:6379&gt; get k1(nil) 在事务执行后，产生的错误，并不会影响事务，其他命令依旧执行 12345678910111213141516127.0.0.1:6379&gt; set k1 v1OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; INCR k1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; EXEC1) (error) ERR value is not an integer or out of range# 出错不会影响其他命令2) OK127.0.0.1:6379&gt; MGET k1 k21) &quot;v1&quot;2) &quot;v2&quot;127.0.0.1:6379&gt; WATCH WATCH可以为Reids提供check-and-set（CAS ）行为。被WATCH的键会被监视， 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败 1234567891011121314151617127.0.0.1:6379&gt; set k1 100OK127.0.0.1:6379&gt; set k2 0OK# 监视k1127.0.0.1:6379&gt; WATCH k1OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; DECRBY k1 20QUEUED127.0.0.1:6379&gt; INCRBY k2 20QUEUED127.0.0.1:6379&gt; EXEC1) (integer) 802) (integer) 20# 没有任何问题 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; WATCH k1OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; DECRBY k1 20QUEUED127.0.0.1:6379&gt; INCRBY k2 20QUEUED# 此时模拟另外一个线程127.0.0.1:6379&gt; get k1&quot;80&quot;127.0.0.1:6379&gt; set k1 800OK################################ 结果事务被取消127.0.0.1:6379&gt; EXEC(nil)127.0.0.1:6379&gt; MGET k1 k21) &quot;800&quot;2) &quot;20&quot;# 流程：监视键，获取键的值，执行事务的时候比对监视的键的值是否发生了变化，如果变化了取消事务，如果没有变化成功执行# 跟Mysql使用version来实现乐观锁是一样的 # 1.获取version# 2.更新时带上version -&gt; set newversion where version=oldversion# 3.如果version不对，就失败！ 如果在 WATCH 执行之后， EXEC 执行之前， 有其他客户端修改了 mykey 的值， 那么当前客户端的事务就会失败，这种形式就被称作乐观锁 取消监视 当 EXEC 被调用时， 不管事务是否成功执行， 对所有键的监视都会被取消。 当客户端断开连接时， 该客户端对键的监视也会被取消。 使用无参数的 UNWATCH 命令可以手动取消对所有键的监视 Jeids Jedis是Redis官方推荐的Java连接工具，使用Java操作Redis中间件。 使用Java操作Redis一定要对Jedis十分熟悉 异常: Exception in thread &quot;main&quot; redis.clients.jedis.exceptions.JedisConnectionException: Failed connecting to 192.168.45.113:6379 关闭防火墙 redis.conf 69行左右注释掉 异常： Exception in thread &quot;main&quot; redis.clients.jedis.exceptions.JedisDataException: DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password 关闭保护模式！ 常用APIStrings 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package cn.this52.main;import redis.clients.jedis.Jedis;import java.util.List;import java.util.Set;public class StringsTest &#123; public static void main(String[] args) throws InterruptedException &#123; try (Jedis jedis = new Jedis(&quot;192.168.45.113&quot;)) &#123; // flushDB 清空数据库 String s = jedis.flushDB(); System.out.println(&quot;清空数据库:&quot; + s); String k1 = jedis.set(&quot;k1&quot;, &quot;v1&quot;); System.out.println(&quot;返回值:&quot; + k1); String v1 = jedis.get(&quot;k1&quot;); System.out.println(&quot;v1:&quot; + v1); System.err.println(&quot;************************&quot;); // set 设置字符串 mset 批量设置字符串 // get 获取字符串 mget 批量获取字符串 String kv = jedis.mset(&quot;k2&quot;, &quot;2&quot;, &quot;k3&quot;, &quot;33&quot;); System.out.println(&quot;批量设置:&quot; + kv); List&lt;String&gt; mget = jedis.mget(&quot;k2&quot;, &quot;k3&quot;); mget.forEach(k -&gt; System.out.println(&quot;k:&quot; + k)); // incr 自增 incrBy 自增指定值 decr自减 decrBy 自减指定值 Long k21 = jedis.incrBy(&quot;k2&quot;, 10); Long k31 = jedis.incr(&quot;k3&quot;); System.out.println(&quot;k2自增10：&quot; + k21); System.out.println(&quot;k3自增1：&quot; + k31); Long k22 = jedis.decr(&quot;k2&quot;); System.out.println(&quot;k2自减1：&quot; + k22); System.out.println(); Boolean k2 = jedis.exists(&quot;k2&quot;); System.out.println(&quot;k2是否存在:&quot; + k2); Set&lt;String&gt; keys = jedis.keys(&quot;*&quot;); System.out.println(&quot;所有的key:&quot; + keys); Long k3 = jedis.setnx(&quot;k3&quot;, &quot;3&quot;); System.out.println(&quot;k3不存在时设置k3=3,结果:&quot; + k3); System.out.println(&quot;k3:&quot; + jedis.get(&quot;k3&quot;)); String k4 = jedis.setex(&quot;k4&quot;, 10, &quot;4&quot;); System.out.println(&quot;设置一个字符串k4=4,过期时间为30s:&quot; + k4); // 让程序睡1s 不然看不出效果 Thread.sleep(1000); System.out.println(&quot;k4剩余时间:&quot; + jedis.ttl(&quot;k4&quot;)); System.out.println(&quot;k4剩余时间:&quot; + jedis.ttl(&quot;k4&quot;)); Thread.sleep(3000); System.out.println(&quot;k4剩余时间:&quot; + jedis.ttl(&quot;k4&quot;)); System.out.println(&quot;k4剩余时间:&quot; + jedis.ttl(&quot;k4&quot;)); Long k11 = jedis.expire(&quot;k1&quot;, 10); System.out.println(&quot;expire设置过期时间:&quot; + k11); // 只剩下k2 k3 String k23 = jedis.getSet(&quot;k2&quot;, &quot;111&quot;); System.out.println(&quot;getset:&quot; + k23); System.out.println(&quot;k2=&quot; + jedis.get(&quot;k2&quot;)); System.out.println(); System.out.println(); String set = jedis.set(&quot;h1&quot;, &quot;hello&quot;); String set2 = jedis.set(&quot;h2&quot;, &quot;world&quot;); System.out.println(&quot;h1=&quot; + jedis.get(&quot;h1&quot;)); System.out.println(&quot;h2=&quot; + jedis.get(&quot;h2&quot;)); Long hello = jedis.strlen(&quot;h1&quot;); System.out.println(&quot;strlen结果:&quot; + hello); Long append = jedis.append(&quot;h1&quot;, jedis.get(&quot;h2&quot;)); // 返回字符串的长度 System.out.println(&quot;将h2append到h1上，结果:&quot; + append); System.out.println(&quot;h1=&quot; + jedis.get(&quot;h1&quot;)); System.out.println(&quot;h2=&quot; + jedis.get(&quot;h2&quot;)); String h1 = jedis.getrange(&quot;h1&quot;, 0, 3); System.out.println(&quot;截取h1[0,3]结果:&quot; + h1); String h2 = jedis.getrange(&quot;h1&quot;, 0, -1); System.out.println(&quot;截取h1[0,-1]结果:&quot; + h2); Long setrange = jedis.setrange(&quot;h2&quot;, 3, &quot;ll&quot;); System.out.println(&quot;覆盖h2索引从3开始的值:&quot; + setrange); System.out.println(&quot;h2=&quot; + jedis.get(&quot;h2&quot;)); &#125; &#125; &#125; Lists 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980&gt;package cn.this52.main;&gt;import redis.clients.jedis.Jedis;&gt;import redis.clients.jedis.ListPosition;&gt;import java.util.List;&gt;public class ListsTest &#123; public static void main(String[] args) &#123; Long del; try (Jedis jedis = new Jedis(&quot;192.168.45.113&quot;)) &#123; jedis.flushDB(); Long list1 = jedis.lpush(&quot;list1&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;5&quot;, &quot;1&quot;); System.out.println(&quot;lpush结果:&quot; + list1); List&lt;String&gt; list11 = jedis.lrange(&quot;list1&quot;, 0, 2); List&lt;String&gt; list12 = jedis.lrange(&quot;list1&quot;, 0, -1); System.out.println(&quot;lrange[0,2]结果:&quot; + list11); System.out.println(&quot;lrange[0,-1]结果:&quot; + list12); Long rpush = jedis.rpush(&quot;list1&quot;, &quot;33&quot;, &quot;44&quot;); System.out.println(&quot;rpush结果:&quot; + rpush); System.out.println(jedis.lrange(&quot;list1&quot;, 0, -1)); String lsit1 = jedis.type(&quot;list1&quot;); System.out.println(&quot;list1类型=&quot; + lsit1); System.out.println(&quot;所有key&quot; + jedis.keys(&quot;*&quot;)); String list13 = jedis.lpop(&quot;list1&quot;); System.out.println(&quot;弹出list1列表的第一个值：&quot; + list13); String list14 = jedis.rpop(&quot;list1&quot;); System.out.println(&quot;弹出list1列表的最后一个值：&quot; + list14); System.out.println(&quot;lrange[0,-1]结果:&quot; + jedis.lrange(&quot;list1&quot;, 0, -1)); String list = jedis.lindex(&quot;list1&quot;, 2); System.out.println(&quot;list1列表的第三个值：&quot; + list); System.out.println(); Long list15 = jedis.llen(&quot;list1&quot;); System.out.println(&quot;list1列表的长度：&quot; + list15); Long list16 = jedis.lrem(&quot;list1&quot;, 1, &quot;2&quot;); // count 个数，可以移除多个相同的值 System.out.println(&quot;移除list1列表中的一个‘2’:&quot; + list16); System.out.println(&quot;lrange[0,-1]结果:&quot; + jedis.lrange(&quot;list1&quot;, 0, -1)); System.out.println(); // 移除源列表的最后一个值到新的列表 String rpoplpush = jedis.rpoplpush(&quot;list1&quot;, &quot;list2&quot;); System.out.println(&quot;移除源列表的最后一个值到新的列表:&quot; + rpoplpush); System.out.println(&quot;list1结果:&quot; + jedis.lrange(&quot;list1&quot;, 0, -1)); System.out.println(&quot;list2结果:&quot; + jedis.lrange(&quot;list2&quot;, 0, -1)); Boolean list17 = jedis.exists(&quot;list1&quot;); Boolean list18 = jedis.exists(&quot;list3&quot;); System.out.println(&quot;list1是否存在：&quot; + list17); System.out.println(&quot;list3是否存在：&quot; + list18); System.out.println(); // set 会从指定索引往后覆盖 String list2 = jedis.lset(&quot;list2&quot;, 0, &quot;99&quot;); // Exception in thread &quot;main&quot; redis.clients.jedis.exceptions.JedisDataException: ERR no such key // key不存在时不能设置 // String list3 = jedis.lset(&quot;list3&quot;, 0, &quot;99&quot;); System.out.println(&quot;设置list2第一个元素为99：&quot; + list2); System.out.println(&quot;list2结果:&quot; + jedis.lrange(&quot;list2&quot;, 0, -1)); // System.out.println(&quot;设置list3第一个元素为99：&quot;+list3); System.out.println(); Long linsert = jedis.linsert(&quot;list1&quot;, ListPosition.BEFORE, &quot;3&quot;, &quot;4&quot;); System.out.println(&quot;往list1列表中的3前面插入4：&quot; + linsert); System.out.println(&quot;list1结果:&quot; + jedis.lrange(&quot;list1&quot;, 0, -1)); Long linsert2 = jedis.linsert(&quot;list1&quot;, ListPosition.AFTER, &quot;1&quot;, &quot;0&quot;); System.out.println(&quot;往list1列表中的1后面插入0：&quot; + linsert2); System.out.println(&quot;list1结果:&quot; + jedis.lrange(&quot;list1&quot;, 0, -1)); System.out.println(jedis.keys(&quot;*&quot;)); del = jedis.del(&quot;list1&quot;, &quot;list2&quot;); System.out.println(del); &#125; &#125;&gt;&#125; SpringBoot整合使用SpringBoot-Data–Redis 在SpringBoot2.xhou1,原来的jedis被替换成了lettuce 引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 配置yaml 1234spring: redis: host: 192.168.45.113 # host默认localhost port默认6379 测试类 12345678910111213141516171819202122232425262728293031323334353637383940414243 package cn.this52.springbootdataredis;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.data.redis.core.RedisTemplate;@SpringBootTestclass SpringbootDataRedisApplicationTests &#123; @Autowired private RedisTemplate&lt;Object,Object&gt; redisTemplate; @Test void contextLoads() &#123; /** * opsForValue() 操作字符串 * opsForList() 操作列表 * opsForHash() 操作哈希 * opsForSet() 操作集合 * opsForZSet() 操作有序集合 * opsForGeo() 地理空间 * opsForHyperLogLog() 基数 * opsForCluster 集群操作 * * * redisTemplate.multi(); // 开启事务 * redisTemplate.exec(); // 执行事务 * redisTemplate.discard(); // 放弃事务 * redisTemplate.watch(); // 监视 * redisTemplate.unwatch(); // 取消监视 * ...... */// RedisConnection connection = redisTemplate.getConnectionFactory().getConnection();// connection.flushDb(); redisTemplate.opsForValue().set(&quot;china&quot;,&quot;中国&quot;); System.out.println(redisTemplate.opsForValue().get(&quot;china&quot;)); System.out.println(redisTemplate.keys(&quot;key&quot;)); &#125;&#125; Redis自动配置类 配置属性类 可以看到数据库，主机，端口什么的，然后熟悉的prefix，这里的变量我们都能在配置文件里面配置 Redis.conf启动服务就需要通过配置文件来启动 单位：k、kb、m、mb、g、bg 配置文件units单位对大小写不敏感 引入INCLUDES 可以引入多个配置文件 网络NETWORK 123&gt;&gt;#69行 bind 127.0.0.1 绑定的ip&gt;&gt;#88行 protected-mode yes 保护模式，默认开启的&gt;&gt;#92行 port 6379 #默认端口 通用GENERAL 12345678910111213141516&gt;&gt;#136行 daemonize yes 开启守护进程，默认关闭&gt;&gt;#158行 pidfile /var/run/redis_6379.pid 如果以守护进程运行就需要一个pid文件&gt;&gt;#日志&gt;&gt;160 # Specify the server verbosity level.&gt;&gt;161 # This can be one of:&gt;&gt;162 # debug (a lot of information, useful for development/testing)&gt;&gt;163 # verbose (many rarely useful info, but not a mess like the debug level)&gt;&gt;164 # notice (moderately verbose, what you want in production probably)&gt;&gt;165 # warning (only very important / critical messages are logged)&gt;&gt;166 loglevel notice&gt;&gt;171 logfile &quot;&quot; # 日志文件位置&gt;&gt;186 databases 16 # 默认16个数据库&gt;&gt;194 always-show-logo yes # 是否开启服务启动时的logo 快照SNAPSHOTTING 1234567891011&gt;&gt;# 持久化，在多少时间内执行多少次会持久化&gt;&gt;# redis是内存数据库，必须要持久化，不然可能会丢失数据&gt;&gt;#218 save 900 1&gt;&gt;#219 save 300 10&gt;&gt;#220 save 60 10000&gt;&gt;#235 stop-writes-on-bgsave-error yes 持久化失败是否还要继续工作&gt;&gt;#241 rdbcompression yes 是否压缩rdb(持久化文件)文件&gt;&gt;#250 rdbchecksum yes 对rdb文件进行错误校验&gt;&gt;#263 dir ./ 文件保存目录 主从复制REPLICATTION 安全SECURITY 1&gt;507 # requirepass foobared 设置密码，默认没有密码 也可以通过命令来设置 12345678910111213&gt;127.0.0.1:6379&gt; config get requirepass&gt;1) &quot;requirepass&quot;&gt;2) &quot;&quot;&gt;127.0.0.1:6379&gt; config set requirepass root&gt;OK&gt;127.0.0.1:6379&gt; config get requirepass&gt;(error) NOAUTH Authentication required.&gt;127.0.0.1:6379&gt; AUTH root&gt;OK&gt;127.0.0.1:6379&gt; config get requirepass&gt;1) &quot;requirepass&quot;&gt;2) &quot;root&quot;&gt;# 此时没有权限是不能操作的 客户端CLIENTS 1&gt;539 # maxclients 10000 最大连接数，默认10000 内存管理MEMORY MANAGEMENT 12345&gt;566 # maxmemory &lt;bytes&gt; 最大内存&gt;597 # maxmemory-policy noeviction 内存上限处理策略# 移除过期key# 报错# ... redis 中的默认的过期策略是 volatile-lru 。 设置方式 1&gt;config set maxmemory-policy volatile-lru maxmemory-policy 六种方式1、volatile-lru：只对设置了过期时间的key进行LRU（默认值） 2、allkeys-lru ： 删除lru算法的key 3、volatile-random：随机删除即将过期key 4、allkeys-random：随机删除 5、volatile-ttl ： 删除即将过期的 6、noeviction ：** 永不过期，返回错误 APPEND ONLY MODE AOF配置 123456&gt;#699 appendonly no 默认不开启，默认是使用red方式持久化的&gt;#703 appendfilename &quot;appendonly.aof&quot; aof持久化文件名&gt;728 # appendfsync always 每次修改都会同步，消耗性能&gt;729 appendfsync everysec 每秒执行一次 sync&gt;730 # appendfsync no 不同步 Redis持久化redis是一个内存数据库，数据保存在内存中，但是我们都知道内存的数据变化是很快的，也容易发生丢失。 Redis提供了持久化的机制，分别是RDB和AOF RDB（REDIS DATABASE） RDB触发机制 save规则满足的时候 save 是同步的，不会消耗额外内存 会阻塞客户端命令，save时无法处理命令 bgsave 异步，需要fork，消耗内存 会在fork发生阻塞，不会阻塞客户端命令 执行FLUSHALL命令的时候 退出redis服务时 恢复rdb文件 只需要简化reb文件放在redis.conf中配置的dir目录即可，redis启动时会自动检查dump.rdb，然后为我们恢复其中的数据 123127.0.0.1:6379&gt; CONFIG GET dir1) &quot;dir&quot;2) &quot;/usr/local/bin&quot; 优点： 适合大规模的数据恢复 对数据的完整性不高和一致性不高，RBD是很好的选择 缺点: 数据的完整性和一致性不高，因为RBD可能在最后一次备份时宕机了 fork子进程持久化数据的时候比较耗费性能，(因为RDB持久化时会先写入临时文件，然后在替换之前的备份文件，此时内存中存在两份数据) AOF（Append Only File）每当有一个写命令过来时，就直接保存在我们的AOF文件中。，就像记录日志一样 AOF保存的是appendonly.aof append 默认是不开启的，改为yes即可 如果aof文件有错误，客户端是不能连接的，此时我们需要用redis给我们提供的工具来修复它redis-check-aof 这个修复会把错误命令删除掉。 配置 123456#699 appendonly no 默认不开启，默认是使用red方式持久化的#703 appendfilename &quot;appendonly.aof&quot; aof持久化文件名728 # appendfsync always 每次修改都会同步，消耗性能729 appendfsync everysec 每秒执行一次 sync730 # appendfsync no 不同步 优点： 可以每次修改都同步，文件完整性会更好 每秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点： 相对于数据文件来说，aof远远大于rdb，修复的速度也比rdb慢 AOF开启后，支持的写QPS会比RDB支持的写QPS低 AOF 在过去曾经发生过这样的 bug ： 因为个别命令的原因，导致 AOF 文件在重新载入时，无法将数据集恢复成保存时的原样 Redis在AOF文件过大时，会fork一个线程自动在后台对数据进行重写，重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的 AOF重写因为 AOF 的运作方式是不断地将命令追加到文件的末尾， 所以随着写入命令的不断增加， AOF 文件的体积也会变得越来越大。 举个例子， 如果你对一个计数器调用了 100 次 INCR key ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录（entry）。 然而在实际上， 只使用set key value命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。 Redis2.4会自动触发AOF重写 扩展文档 Redis发布与订阅Redis 通过 PUBLISH 、 SUBSCRIBE等命令实现了订阅与发布模式， 这个功能提供两种信息机制， 分别是订阅/发布到频道和订阅/发布到模式。 频道的订阅与信息发送Redis 的 SUBSCRIBE命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端。 频道：channel1 三个客户端：client1，client2，client5 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： 订阅端： 123456789101112127.0.0.1:6379&gt; SUBSCRIBE aurora # 订阅一个频道 auroraReading messages... (press Ctrl-C to quit)1) &quot;subscribe&quot;2) &quot;aurora&quot;3) (integer) 1# 等待读取发布的消息1) &quot;message&quot; # 消息2) &quot;aurora&quot; # 频道3) &quot;msg&quot; # 内容1) &quot;message&quot;2) &quot;aurora&quot;3) &quot;hello,aurora&quot; 频道端： 1234127.0.0.1:6379&gt; PUBLISH aurora msg # 发布一个消息(integer) 1127.0.0.1:6379&gt; PUBLISH aurora hello,aurora(integer) 1 Redis主从复制概念主从复制，读写分离。大部分情况下都是在进行读操作，可以减缓服务器的压力 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。 默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点，从节点也能有多个从节点。 主从复制的作用 主从复制的作用主要包括： 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 环境配置主从复制，只配置从节点，不需要配置主节点 123456789101112131415## 查看当前节点信息127.0.0.1:6379&gt; INFO replication# Replicationrole:master # 角色 masterconnected_slaves:0 # 没有从机master_replid:8ef6b543c26f2812682f22d2ee30423baca85fe8master_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0127.0.0.1:6379&gt; 一主二从 注意事项： 主节点的bind需要配置为0.0.0.0或者注释，不然无法挂载 主节点需要关闭保护模式，或者在从节点中配置masterauth 主节点[192.168.45.113] 1# 可以看到当前是没有任何从节点的 从节点[192.168.45.111] 1234# 使用 SLAVEOF HOST PORT 来配置主节点 SLAVEOF 192.168.45.113 6379# 此时可以看到信息 # 角色：slave # 主节点主机：192.168.45.113 端口号：6379 连接状态：连接中 ...等等信息 从节点[192.168.45.112] 1#跟192.168.45.111节点信息是一样的，然后我们看下主节点信息 123# 可以看到从节点连接数为2，以及从节点的各种信息# 关闭主从复制命令 SLAVEOF NO ONE 真实的主从配置应该去配置文件中配置，才能永久生效。命令开启的只是暂时的 主节点挂掉后恢复，依然还是主节点，从节点会自动连接上来 主写从读主机负责写，从机负责读，从机是不能写的 复制原理 slave启动成功连接到master后会发送sysnc命令，master启动一个后台进程将数据库快照保存到RDB文件中（此时如果生成 RDB 文件过程中存在写数据操作会导致 RDB 文件和当前主 redis 数据不一致，所以此时 master 主进程会开始收集写命令并缓存起来，最后再把转发给slave。），然后发送给slave，slave将文件保存到磁盘上，然后恢复到内存中。 后续 master 收到的写命令都会通过开始建立的连接发送给 slave。 当 master 和 slave 的连接断开时 slave 可以自动重新建立连接。如果 master 同时收到多个 slave 发来的同步连接命令，只会启动一个进程来写数据库镜像，然后发送给所有 slave。 全量复制和增量复制在Redis2.8前，每次都会全量复制，当从节点停止运行后，在启动可能只有少量数据不同步，此时从节点依旧会复制全部数据，这样性能很低 之后会判断是否是首次同步，不是首次master只会发送非同步的数据，这样就提高了性能。 扩展： 从机连接主机后，会主动发起 PSYNC 命令，从机会提供 master 的 runid(机器标识，随机生成的一个串) 和 offset（数据偏移量，如果offset主从不一致则说明数据不同步），主机验证 runid 和 offset 是否有效，runid 相当于主机身份验证码，用来验证从机上一次连接的主机，如果 runid 验证未通过则，则进行全同步，如果验证通过则说明曾经同步过，根据 offset 同步部分数据。 扩展：手动选举 当主节点挂掉的时候我们可以使用SLAVE NO ONE命令让从节点变成主节点，其他从节点会自动选择主节点。 主节点恢复后只是一个单独的节点。 哨兵模式简介主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例 哨兵作用 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 哨兵也可能会出现问题，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，形成多哨兵模式。 实践测试 前提要求： 123#主从服务器的reids.conf 配置bind 0.0.0.0接受所有ip请求 首先把redis目录里面的sentinel.conf拷贝一份过来 然后配置一下主节点host等信息 1234#121 sentinel monitor mymaster 192.168.45.113 6379 2#sentinel monitor 被监控的主机名称（默认mymaster即可） host port 2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作# host为主节点ip 先启动主服务器redis服务，然后启动从服务器，最后开启哨兵 此时没有任何从节点 112连接上主节点 111连接上主节点 开启三个主机的哨兵 测试主从复制没有问题，然后测试113宕机 可以看到主节点从113变成了111 然后重启113的服务 选取主节点后，哨兵会自动修改sentinel.conf中的监控配置 SpringBoot操作哨兵模式 配置哨兵模式 哨兵集群需要配置多节点（否则是没有意义的）！ 代码测试没问题 哨兵模式优缺点优点： 哨兵集群是基于主从复制的，所有主从复制的优点他都有 高可用，在主节点故障时能实现故障转移 哨兵模式就是主从复制的升级，手动到自动，更加健壮 缺点： 没办法做到水平扩展 主服务器宕机后，故障转移那段时间，服务是不可用的 依旧无法解决单节点并发、吞吐量，物理上限等问题 运维复杂，哨兵模式配置起来其实是很麻烦的 Cluster集群 实现高可用 架构特点： 所有的 redis 节点彼此互联 (PING-PONG 机制)，内部使用二进制协议优化传输速度和带宽。 节点的 fail 是通过集群中超过半数的节点检测失效或者某个节点主从全挂时才生效。 客户端与 redis 节点直连，不需要中间 proxy 层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。 redis-cluster 把所有的物理节点映射到 [0-16383]slot 上 slot = CRC16（key）&amp; 16383 Redis 集群一般由 多个节点 组成，节点数量至少为 6 个，才能保证组成 完整高可用 的集群 集群搭建123# 创建一个文件夹放配置文件mkdir rediscluster# 复制6份配置文件过来 1234567891011# 修改配置文件bind 0.0.0.0 #访问ipport 7000 #端口7000-7005daemonize yes #守护进程pidfile /var/run/redis_7000.pid #进程pid文件dbfilename dump7000.rdb #rdb持久化文件appendonly yes #开启aof持久化appendfilename &quot;appendonly7000.aof&quot; #aof持久化文件cluster-enabled yes #开启集群cluster-config-file nodes-7000.conf #集群节点文件cluster-node-timeout 5000 #集群连接超时时间 123456789101112# 创建启动脚本vim redis-start.shredis-server rediscluster/redis-7000.confredis-server rediscluster/redis-7001.confredis-server rediscluster/redis-7002.confredis-server rediscluster/redis-7003.confredis-server rediscluster/redis-7004.confredis-server rediscluster/redis-7005.conf#保存退出，给予权限chmod +x redis-start.sh 123456#启动集群./redis-start.sh#创建集群redis-cli --cluster create 192.168.45.121:7000 192.168.45.121:7001 192.168.45.121:7002 192.168.45.121:7003 192.168.45.121:7004 192.168.45.121:7005 --cluster-replicas 1#-replicas 1 代表1个maste 1一个salve 集群测试1234# 查看集群信息redis-cli --cluster check [host]:[port] # 集群任意节点redis-cli --cluster check 192.168.45.121:7001 1234#客户端以集群方式登录redis-cli -c -h [host] -p [port] #-c代表以集群方式连接redisredis-cli -c -h 192.168.45.121 -p 7000 #集群任意节点 12# 存储和获取key的时候，会根据计算出来的槽不断地重定向到对应客户端，这是redis cluster在设计时就考虑到了去中心化# 客户端默认只能从 Master 节点上获取数据，不能从 Slave 节点获取；如果需要直接从 Slave 节点获取数据，客户端可以设置为 readonly 模式 集群故障切换测试 123# 模拟崩溃7001redis-cli -p 7001 debug segfault#debug segfault 命令执行一个非法的内存访问从而让 Redis 崩溃，仅在开发时用于 bug 调试。 123# 添加节点redis-cli --cluster add-node [host:port] [host:port] #第一个参数为新加入节点 #第二个参数为集群任意节点redis-cli --cluster add-node 192.168.45.121:7006 192.168.45.121:7000 redis-cli -cluster命令1234567891011121314151617181920212223242526272829303132333435363738redis-cli --cluster helpCluster Manager Commands: create host1:port1 ... hostN:portN #创建集群 --cluster-replicas &lt;arg&gt; #从节点个数 check host:port #检查集群 --cluster-search-multiple-owners #检查是否有槽同时被分配给了多个节点 info host:port #查看集群状态 fix host:port #修复集群 --cluster-search-multiple-owners #修复槽的重复分配问题 reshard host:port #指定集群的任意一节点进行迁移slot，重新分slots --cluster-from &lt;arg&gt; #需要从哪些源节点上迁移slot，可从多个源节点完成迁移，以逗号隔开，传递的是节点的node id，还可以直接传递--from all，这样源节点就是集群的所有节点，不传递该参数的话，则会在迁移过程中提示用户输入 --cluster-to &lt;arg&gt; #slot需要迁移的目的节点的node id，目的节点只能填写一个，不传递该参数的话，则会在迁移过程中提示用户输入 --cluster-slots &lt;arg&gt; #需要迁移的slot数量，不传递该参数的话，则会在迁移过程中提示用户输入。 --cluster-yes #指定迁移时的确认输入 --cluster-timeout &lt;arg&gt; #设置migrate命令的超时时间 --cluster-pipeline &lt;arg&gt; #定义cluster getkeysinslot命令一次取出的key数量，不传的话使用默认值为10 --cluster-replace #是否直接replace到目标节点 rebalance host:port #指定集群的任意一节点进行平衡集群节点slot数量 --cluster-weight &lt;node1=w1...nodeN=wN&gt; #指定集群节点的权重 --cluster-use-empty-masters #设置可以让没有分配slot的主节点参与，默认不允许 --cluster-timeout &lt;arg&gt; #设置migrate命令的超时时间 --cluster-simulate #模拟rebalance操作，不会真正执行迁移操作 --cluster-pipeline &lt;arg&gt; #定义cluster getkeysinslot命令一次取出的key数量，默认值为10 --cluster-threshold &lt;arg&gt; #迁移的slot阈值超过threshold，执行rebalance操作 --cluster-replace #是否直接replace到目标节点 add-node new_host:new_port existing_host:existing_port #添加节点，把新节点加入到指定的集群，默认添加主节点 --cluster-slave #新节点作为从节点，默认随机一个主节点 --cluster-master-id &lt;arg&gt; #给新节点指定主节点 del-node host:port node_id #删除给定的一个节点，成功后关闭该节点服务 call host:port command arg arg .. arg #在集群的所有节点执行相关命令 set-timeout host:port milliseconds #设置cluster-node-timeout import host:port #将外部redis数据导入集群 --cluster-from &lt;arg&gt; #将指定实例的数据导入到集群 --cluster-copy #migrate时指定copy --cluster-replace #migrate时指定replace help For check, fix, reshard, del-node, set-timeout you can specify the host and port of any working node in the cluster. SpringBoot操作Cluster Redis缓存穿透和雪崩缓存穿透 Redis实现分布式Session管理机制 ​ redis的session管理是利用spring提供的session管理解决方案，将一个应用的session存储到redis上，整个应用session请求都回去redis中获取sessin数据 开发Session管理1.引入依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.session&lt;/groupId&gt; &lt;artifactId&gt;spring-session-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置RedisSession123456789package cn.this52.sessionredis.config;import org.springframework.context.annotation.Configuration;import org.springframework.session.data.redis.config.annotation.web.http.EnableRedisHttpSession;@Configuration@EnableRedisHttpSession //将整个应用session放到redis管理public class RedisSessionManager &#123;&#125; 3.配置redis集群1234spring: redis: cluster: nodes: 192.168.45.121:7000,192.168.45.121:7001,192.168.45.121:7002,192.168.45.121:7003,192.168.45.121:7004,192.168.45.121:7005 4.测试代码123456789101112131415161718192021222324252627282930313233343536373839404142package cn.this52.sessionredis.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.util.ArrayList;import java.util.List;@Controllerpublic class TestController &#123; @RequestMapping(&quot;test&quot;) public void tes(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; List&lt;String&gt; list = (List&lt;String&gt;) request.getSession().getAttribute(&quot;list&quot;); if (list == null) &#123; list = new ArrayList&lt;&gt;();// request.getSession().setAttribute(&quot;list&quot;, list); &#125; list.add(&quot;111&quot;); /* * 每次seesion发生变化都需要setAttribute才能存入redis，否则影响的只是Jvm中的list,redis中存入的list的size永远是1 * */ request.getSession().setAttribute(&quot;list&quot;, list); response.getWriter().println(&quot;size=&gt;&gt;:&quot; + list.size()); response.getWriter().print(&quot;seesionid=&gt;&gt;:&quot; + request.getSession().getId()); &#125; /** * 销毁session，如果不做任何处理，则RequestMapping必须写二级路径映射，否则会报错 */ @RequestMapping(&quot;te/logout&quot;) public void logout(HttpServletRequest request) throws IOException &#123; request.getSession().invalidate(); &#125;&#125; 5.打war包测试123456&lt;!-- 排除内嵌tomcat--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 打包时报错Failed to execute goal org.apache.maven.plugins:maven-war-plugin:2.2:war (default-war) on project session-redis: Error assembling WAR: webxml attribute is required (or pre-existing WEB-INF/web.xml if executing in update mode) 引入插件解决 12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;failOnMissingWebXml&gt;false&lt;/failOnMissingWebXml&gt; &lt;/configuration&gt;&lt;/plugin&gt; 6.部署到Linux 测试OK springboot Rdis集群 当一个redis节点宕机后，程序依旧报错command timeout，还未解决","categories":[{"name":"Nosql","slug":"Nosql","permalink":"https://blog.this52.cn/categories/Nosql/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://blog.this52.cn/tags/Redis/"},{"name":"Nosql","slug":"Nosql","permalink":"https://blog.this52.cn/tags/Nosql/"},{"name":"缓存","slug":"缓存","permalink":"https://blog.this52.cn/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Shiro随记","slug":"Shiro","date":"2020-07-14T16:00:00.000Z","updated":"2020-07-14T16:00:00.000Z","comments":true,"path":"posts/6873a336/","link":"","permalink":"https://blog.this52.cn/posts/6873a336/","excerpt":"","text":"ShiroApache Shiro是一个功能强大且灵活的开源安全框架,主要功能包括用户认证、授权、会话管理以及加密。 Shiro简单灵活 四大功能： 认证：验证用户是谁，能否登陆 授权：验证用户是否有权限，可以访问那些资源 会话管理：即使在非Web或EJB应用程序中，也可以管理用户特定的会话 加密：对数据进行加密，保证安全 其他功能支持： Web支持：Shiro的Web支持API可帮助轻松保护Web应用程序。 缓存：缓存是Apache Shiro API的第一层公民，可确保安全操作保持快速有效。 并发性：Apache Shiro的并发功能支持多线程应用程序。 测试：测试支持可以帮助您编写单元测试和集成测试，并确保您的代码将按预期进行保护。 “运行方式”：一种功能，允许用户采用其他用户的身份（如果允许），有时在管理方案中很有用。 “记住我”：在各个会话中记住用户的身份，因此他们仅在必要时登录。 Shiro组件 Subject：把当前用户作为一个主体，通过subject进行授权认证 SecurityManager：安全管理器，对全部的subject进行安全管理 Authenticator：认证 Authorizer：授权 Realm：领域，相当于数据源 Shiro过滤器 SpringBoot整合Shiro 整合了授权认证、MD5盐值加密、thymeleaf、EhCache、Redis Yaml1234567891011121314151617spring: application: name: springboot-shiro datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/shiro?useSSL=true username: root password: root redis: port: 6379 host: password: &#x27;070409&#x27;mybatis-plus: configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl mapper-locations: classpath:/mapper/* type-aliases-package: cn.this52.springbootshiro.pojo ShiroConfig12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package cn.this52.springbootshiro.config;import at.pollux.thymeleaf.shiro.dialect.ShiroDialect;import cn.this52.springbootshiro.realm.UserRealm;import org.apache.shiro.authc.credential.HashedCredentialsMatcher;import org.apache.shiro.cache.ehcache.EhCacheManager;import org.apache.shiro.spring.web.ShiroFilterFactoryBean;import org.apache.shiro.web.mgt.DefaultWebSecurityManager;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.LinkedHashMap;import java.util.Map;@Configurationpublic class ShiroConfig &#123;// Shiro配置 @Bean public ShiroFilterFactoryBean shiroFilterFactoryBean(DefaultWebSecurityManager securityManager) &#123; ShiroFilterFactoryBean shiro = new ShiroFilterFactoryBean(); shiro.setSecurityManager(securityManager); // 权限设置 Map&lt;String, String&gt; auth = new LinkedHashMap&lt;&gt;(); auth.put(&quot;/main&quot;, &quot;authc&quot;); // main请求需要认证 auth.put(&quot;/manager&quot;, &quot;perms[manager]&quot;); // manager请求需要有manager权限 auth.put(&quot;/admin&quot;, &quot;roles[admin]&quot;); // admin请求需要有admin角色 // login页面 shiro.setLoginUrl(&quot;/login&quot;); // 未授权页面 shiro.setUnauthorizedUrl(&quot;/unAuth&quot;); shiro.setFilterChainDefinitionMap(auth); return shiro; &#125; /** * 安全管理器 * * @param userRealm realm * @return DefaultWebSecurityManager */ @Bean public DefaultWebSecurityManager securityManager(UserRealm userRealm) &#123; return new DefaultWebSecurityManager(userRealm); &#125; /** * 注入Realm，配置MD5加密 * * @return UserRealm */ @Bean public UserRealm userRealm() &#123; UserRealm userRealm = new UserRealm(); // 修改凭证匹配器并设置加密算法 HashedCredentialsMatcher hashedCredentialsMatcher = new HashedCredentialsMatcher(&quot;md5&quot;); // 设置散列次数 hashedCredentialsMatcher.setHashIterations(1024); userRealm.setCredentialsMatcher(hashedCredentialsMatcher); //开启缓存管理(默认是EhCache) userRealm.setCacheManager(new EhCacheManager()); userRealm.setCachingEnabled(true);// 开启全局缓存 userRealm.setAuthenticationCachingEnabled(true);// 开启认证缓存 userRealm.setAuthorizationCachingEnabled(true);// 开启授权缓存 userRealm.setAuthenticationCacheName(&quot;authentication&quot;);// 设置认证缓存名字 userRealm.setAuthorizationCacheName(&quot;authorization&quot;);// 设置授权缓存名字 return userRealm; &#125; /** * 整合thymeleaf配置shiro方言 * * @return shiroDialect */ @Bean public ShiroDialect shiroDialect() &#123; return new ShiroDialect(); &#125;&#125; Controller12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package cn.this52.springbootshiro.controller;import cn.this52.springbootshiro.pojo.User;import cn.this52.springbootshiro.service.UserService;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.IncorrectCredentialsException;import org.apache.shiro.authc.UnknownAccountException;import org.apache.shiro.authc.UsernamePasswordToken;import org.apache.shiro.subject.Subject;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.PostMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class UserController &#123; @Autowired private UserService userService; // 跳转到所有请求的页面，页面不存在时会报错 @GetMapping(&quot;/&#123;url&#125;&quot;) public String forward(@PathVariable String url) &#123; return url; &#125; @PostMapping(&quot;/login&quot;) public String login(User user, Model model) &#123; Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken(user.getUsername(), user.getPassword()); try &#123; subject.login(token); subject.getSession().setAttribute(&quot;user&quot;, subject.getPrincipal()); return &quot;redirect:/index&quot;; &#125; catch (UnknownAccountException e) &#123; e.printStackTrace(); // 用户不存在 model.addAttribute(&quot;msg&quot;, &quot;用户不存在&quot;); return &quot;login&quot;; &#125; catch (IncorrectCredentialsException e) &#123; e.printStackTrace(); // 密码错误 model.addAttribute(&quot;msg&quot;, &quot;密码错误&quot;); return &quot;login&quot;; &#125; &#125; @GetMapping(&quot;/unAuth&quot;) @ResponseBody public String unAuth() &#123; return &quot;未授权无法访问！&quot;; &#125; @GetMapping(&quot;/logout&quot;) public String logout() &#123; SecurityUtils.getSubject().logout(); return &quot;login&quot;; &#125; @PostMapping(&quot;/register&quot;) public String register(User user, Model model) &#123; int register = userService.register(user); model.addAttribute(&quot;msg&quot;, register == 1 ? &quot;注册成功！&quot; : &quot;注册失败！&quot;); return register == 1 ? &quot;login&quot; : &quot;register&quot;; &#125;&#125; Mapper1234567891011121314151617181920212223242526package cn.this52.springbootshiro.mapper;import cn.this52.springbootshiro.pojo.Permission;import cn.this52.springbootshiro.pojo.User;import com.baomidou.mybatisplus.core.mapper.BaseMapper;import org.apache.ibatis.annotations.ResultMap;import org.apache.ibatis.annotations.Select;import java.util.List;public interface UserMapper extends BaseMapper&lt;User&gt; &#123; @ResultMap(&quot;userMap&quot;) @Select(&quot;select uid,username,rid,r_name\\n&quot; + &quot;from user\\n&quot; + &quot; left join user_role ur on uid = ur.user_id\\n&quot; + &quot; left join role on ur.role_id = role.rid where uid =#&#123;uid&#125;&quot;) User findRolesByUid(int uid); @Select(&quot;select p_name\\n&quot; + &quot;from role\\n&quot; + &quot; left join role_perm rp on role.rid = rp.role_id\\n&quot; + &quot; left join permission p on rp.perm_id = p.pid\\n&quot; + &quot;where rid = 1;&quot;) List&lt;Permission&gt; findPermsByRid(int rid);&#125; Pojo123456789@Data@Accessors(chain = true)@AllArgsConstructor@NoArgsConstructorpublic class Permission implements Serializable &#123; private static final long serialVersionUID = -5891141512288426298L; private Integer pid; private String pName;&#125; 123456789101112@Data@Accessors(chain = true)@AllArgsConstructor@NoArgsConstructorpublic class Role implements Serializable &#123; private static final long serialVersionUID = -4021452759620212876L; private Integer rid; private String rName; @TableField(exist = false) List&lt;Permission&gt; permissions;&#125; 123456789101112131415@Data@Accessors(chain = true)@AllArgsConstructor@NoArgsConstructorpublic class User implements Serializable &#123; private static final long serialVersionUID = -265042359335069131L; private Integer uid; private String username; public String password; private String salt; @TableField(exist = false) private List&lt;Role&gt; roles;&#125; Realm123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293package cn.this52.springbootshiro.shiro.realm;import cn.this52.springbootshiro.pojo.Permission;import cn.this52.springbootshiro.pojo.Role;import cn.this52.springbootshiro.pojo.User;import cn.this52.springbootshiro.service.UserService;import cn.this52.springbootshiro.shiro.salt.MyByteSource;import org.apache.shiro.SecurityUtils;import org.apache.shiro.authc.AuthenticationException;import org.apache.shiro.authc.AuthenticationInfo;import org.apache.shiro.authc.AuthenticationToken;import org.apache.shiro.authc.SimpleAuthenticationInfo;import org.apache.shiro.authz.AuthorizationInfo;import org.apache.shiro.authz.SimpleAuthorizationInfo;import org.apache.shiro.realm.AuthorizingRealm;import org.apache.shiro.subject.PrincipalCollection;import org.apache.shiro.subject.Subject;import org.apache.shiro.util.CollectionUtils;import org.springframework.beans.factory.annotation.Autowired;import java.util.List;import java.util.stream.Collectors;public class UserRealm extends AuthorizingRealm &#123; @Autowired private UserService userService; /** * 授权 * * @param principalCollection 用户信息 * @return 授权结果 */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; // 获取当前用户登录信息 Subject subject = SecurityUtils.getSubject(); User user = (User) subject.getPrincipal(); // 用户对应角色权限信息 SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); User rolesByUid = userService.findRolesByUid(user.getUid()); List&lt;Role&gt; roles = rolesByUid.getRoles(); if (!CollectionUtils.isEmpty(roles)) &#123; roles.forEach(role -&gt; &#123; // 添加角色 authorizationInfo.addRole(role.getRName()); // 添加权限 authorizationInfo.addStringPermissions( userService.findPermsByRid(role.getRid()) .stream() .map(Permission::getPName) .collect(Collectors.toList())); &#125;); &#125; return authorizationInfo; &#125; /** * 认证 * * @param authenticationToken 认证令牌 * @return 认证结果 * @throws AuthenticationException 身份验证异常 */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; System.out.println(&quot;=&gt;&gt; 认证&quot;);// 在token中获取用户名 String username = (String) authenticationToken.getPrincipal(); // 用户令牌（包含用户信息）// UsernamePasswordToken token = (UsernamePasswordToken) authenticationToken; User user = userService.findUser(username); // null代表用户不存在 if (user == null) return null; /* * SimpleAuthenticationInfo * Object principal 用户（可以给用户名最好给对象） * Object credentials 密码 * ByteSource credentialsSalt 盐值 * String realmName 当前realm名 * getName() 代表当前Realm */ return new SimpleAuthenticationInfo( user, user.getPassword(), new MyByteSource(user.getSalt()), getName()); &#125;&#125; Service1234567891011121314151617181920212223242526272829303132333435363738394041package cn.this52.springbootshiro.service;import cn.this52.springbootshiro.pojo.Permission;import cn.this52.springbootshiro.pojo.User;import java.util.List;public interface UserService &#123; /** * 根据用户名查找用户 * * @param username 用户名 * @return 用户 */ User findUser(String username); /** * 根据用户id查找角色 * * @param uid 用户id * @return 用户 */ User findRolesByUid(int uid); /** * 根据角色id查找角色权限 * * @param rid 角色id * @return 权限列表 */ List&lt;Permission&gt; findPermsByRid(int rid); /** * 注册 * * @param user 用户实体 * @return 注册结果 */ int register(User user);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package cn.this52.springbootshiro.service;import cn.hutool.core.util.RandomUtil;import cn.this52.springbootshiro.mapper.UserMapper;import cn.this52.springbootshiro.pojo.Permission;import cn.this52.springbootshiro.pojo.User;import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;import org.apache.shiro.crypto.hash.Md5Hash;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import javax.annotation.Resource;import java.util.List;@Service@Transactionalpublic class UserServiceImpl implements UserService &#123; @Resource private UserMapper userMapper; @Override public User findUser(String username) &#123; QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); wrapper.eq(&quot;username&quot;, username); return userMapper.selectOne(wrapper); &#125; @Override public User findRolesByUid(int uid) &#123; return userMapper.findRolesByUid(uid); &#125; @Override public List&lt;Permission&gt; findPermsByRid(int rid) &#123; return userMapper.findPermsByRid(rid); &#125; @Override public int register(User user) &#123; if (findUser(user.getUsername()) != null) &#123; return 0; &#125; String salt = RandomUtil.randomString(10); user.setPassword(new Md5Hash(user.getPassword(), salt, 1024).toHex()); user.setSalt(salt); return userMapper.insert(user); &#125;&#125; CustomRedisTemplate123456789101112131415161718192021package cn.this52.springbootshiro.redis;import org.springframework.context.annotation.Bean;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.StringRedisSerializer;import org.springframework.stereotype.Component;@Componentpublic class CustomRedisTemplate &#123; @Bean public static RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) &#123; RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(redisConnectionFactory); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.setHashKeySerializer(new StringRedisSerializer()); return redisTemplate; &#125;&#125; RedisCache123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package cn.this52.springbootshiro.shiro.cache;import cn.this52.springbootshiro.utils.ApplicationContextUtil;import org.apache.shiro.cache.Cache;import org.apache.shiro.cache.CacheException;import org.springframework.data.redis.core.RedisTemplate;import java.util.Collection;import java.util.Set;/** * 自定义缓存 * * @param &lt;K&gt; * @param &lt;V&gt; */@SuppressWarnings(&quot;all&quot;) //压制警告public class RedisCache&lt;K, V&gt; implements Cache&lt;K, V&gt; &#123; private String cacheName; public RedisCache() &#123; &#125; public RedisCache(String cacheName) &#123; this.cacheName = cacheName; &#125; @Override public V get(K k) throws CacheException &#123; System.out.println(&quot;get k=&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot; + k); Object o = redisTemplate().opsForHash().get(cacheName, k.toString()); System.out.println(&quot;get v=&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot; + o); return (V) o; &#125; @Override public V put(K k, V v) throws CacheException &#123; System.out.println(&quot;put k=&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot; + k); System.out.println(&quot;put v=&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&quot; + v); redisTemplate().opsForHash().put(cacheName, k.toString(), v); return null; &#125; /** * 注销后是否清除授权缓存 * @param k 用户信息 * @return * @throws CacheException */ @Override public V remove(K k) throws CacheException &#123;// return (V) redisTemplate().opsForHash().delete(cacheName, k.toString()); return null; &#125; @Override public void clear() throws CacheException &#123; redisTemplate().delete(cacheName); &#125; @Override public int size() &#123; return redisTemplate().opsForHash().size(cacheName).intValue(); &#125; @Override public Set&lt;K&gt; keys() &#123; return (Set&lt;K&gt;) redisTemplate().opsForHash().keys(cacheName); &#125; @Override public Collection&lt;V&gt; values() &#123; return (Collection&lt;V&gt;) redisTemplate().opsForHash().values(cacheName); &#125; public RedisTemplate&lt;String, Object&gt; redisTemplate() &#123; return (RedisTemplate&lt;String, Object&gt;) ApplicationContextUtil.getBean(&quot;redisTemplate&quot;); &#125;&#125; RedisCacheManger123456789101112131415package cn.this52.springbootshiro.shiro.cache;import org.apache.shiro.cache.Cache;import org.apache.shiro.cache.CacheException;import org.apache.shiro.cache.CacheManager;/** * 自定义缓存管理 */public class RedisCacheManger implements CacheManager &#123; @Override public &lt;K, V&gt; Cache&lt;K, V&gt; getCache(String cacheName) throws CacheException &#123; return new RedisCache&lt;K, V&gt;(cacheName); &#125;&#125; MybyteSource123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package cn.this52.springbootshiro.shiro.salt;import org.apache.shiro.codec.Base64;import org.apache.shiro.codec.CodecSupport;import org.apache.shiro.codec.Hex;import org.apache.shiro.util.ByteSource;import java.io.File;import java.io.InputStream;import java.io.Serializable;import java.util.Arrays;public class MyByteSource implements ByteSource, Serializable &#123; private static final long serialVersionUID = -256381558320083357L; private byte[] bytes; private String cachedHex; private String cachedBase64; public MyByteSource() &#123; &#125; public MyByteSource(byte[] bytes) &#123; this.bytes = bytes; &#125; public MyByteSource(char[] chars) &#123; this.bytes = CodecSupport.toBytes(chars); &#125; public MyByteSource(String string) &#123; this.bytes = CodecSupport.toBytes(string); &#125; public MyByteSource(ByteSource source) &#123; this.bytes = source.getBytes(); &#125; public MyByteSource(File file) &#123; this.bytes = (new MyByteSource.BytesHelper()).getBytes(file); &#125; public MyByteSource(InputStream stream) &#123; this.bytes = (new MyByteSource.BytesHelper()).getBytes(stream); &#125; public static boolean isCompatible(Object o) &#123; return o instanceof byte[] || o instanceof char[] || o instanceof String || o instanceof ByteSource || o instanceof File || o instanceof InputStream; &#125; public byte[] getBytes() &#123; return this.bytes; &#125; public boolean isEmpty() &#123; return this.bytes == null || this.bytes.length == 0; &#125; public String toHex() &#123; if (this.cachedHex == null) &#123; this.cachedHex = Hex.encodeToString(this.getBytes()); &#125; return this.cachedHex; &#125; public String toBase64() &#123; if (this.cachedBase64 == null) &#123; this.cachedBase64 = Base64.encodeToString(this.getBytes()); &#125; return this.cachedBase64; &#125; public String toString() &#123; return this.toBase64(); &#125; public int hashCode() &#123; return this.bytes != null &amp;&amp; this.bytes.length != 0 ? Arrays.hashCode(this.bytes) : 0; &#125; public boolean equals(Object o) &#123; if (o == this) &#123; return true; &#125; else if (o instanceof ByteSource) &#123; ByteSource bs = (ByteSource) o; return Arrays.equals(this.getBytes(), bs.getBytes()); &#125; else &#123; return false; &#125; &#125; private static final class BytesHelper extends CodecSupport &#123; private BytesHelper() &#123; &#125; public byte[] getBytes(File file) &#123; return this.toBytes(file); &#125; public byte[] getBytes(InputStream stream) &#123; return this.toBytes(stream); &#125; &#125;&#125; Utils123456789101112131415161718192021222324252627282930313233343536package cn.this52.springbootshiro.utils;import org.springframework.beans.BeansException;import org.springframework.context.ApplicationContext;import org.springframework.context.ApplicationContextAware;import org.springframework.stereotype.Component;@Componentpublic class ApplicationContextUtil implements ApplicationContextAware &#123; private static ApplicationContext context; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; context = applicationContext; &#125; /** * 根据bean名从ioc容器中取对象 * @param beanName bean名 * @return 实例 */ public static Object getBean(String beanName) &#123; return context.getBean(beanName); &#125; /** * 根据类的class获取对象实例 * @param clazz 类class * @param &lt;T&gt; 返回类型 * @return 实例 */ public static &lt;T&gt; T getBean(Class&lt;T&gt; clazz) &#123; return context.getBean(clazz); &#125;&#125; Pom依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;5.4.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.49&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;1.5.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;1.5.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.theborakompanioni&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-extras-shiro&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 错误 配置缓存后使用devtools热部署会重复创建CacheManager，此时的CacheManager是单例的。 2.配置Shiro缓存后，Realm里面的盐值反序列化失败 原因： 没有实现序列化接口 解决方案： 取消authenticationCache，就不会序列化盐值，自然不会反序列化 自定义ByteSource实现类,可以继承SimpleByteSource，然后实现序列化接口 然后会在序列化的时候没问题了，但是反序列化的时候会发现一个新的错误 那是因为SimpleByteSource没有无参构造，子类也无法写无参构造‘，就会抛出异常 解决方案： 复制SimpleByteSource所有信息到自定以ByteSource中，并实现ByteSource接口以及序列化接口，还得生成无参构造。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/tags/Java/"},{"name":"Shiro","slug":"Shiro","permalink":"https://blog.this52.cn/tags/Shiro/"},{"name":"安全框架","slug":"安全框架","permalink":"https://blog.this52.cn/tags/%E5%AE%89%E5%85%A8%E6%A1%86%E6%9E%B6/"}]},{"title":"Docker随记","slug":"Docker","date":"2020-06-30T16:00:00.000Z","updated":"2020-06-30T16:00:00.000Z","comments":true,"path":"posts/cf5597ac/","link":"","permalink":"https://blog.this52.cn/posts/cf5597ac/","excerpt":"","text":"DockerDocker是什么简单来来说就是将应用程序部署到独立容器，每个容器相当于一个小的linux系统，通过容器进行打包成镜像，放到有Docker环境上的系统上运行。虚拟机也是属于虚拟化技术，Docker容器也是一种虚拟化技术，它是基于Go语言开发的 Docker优势 更快交付/部署 轻量级 相互隔离，互不影响 更便捷的升级和维护 更高效的资源利用 Docker组成 Docker由镜像(images)，容器(container)，仓库(repository)组成; 镜像就像是装系统时的系统盘，包括了一些操作系统之类软件的，它是只读的. 容器可以理解为提供了硬件环境，我们的沉香谷放在里面运行，可以当成一个简易的linux系统。 仓库用来存放镜像，跟git很相似，我们可以从中心仓库下载镜像，也可以自建仓库。也可以把制作好的镜像上传到远程仓库。 仓库分为公开仓库和私有仓库，最大的公开仓库是官方仓库 Dock Hub 安装Docker 环境 centos7 MobaXterm_Personal 123456789101112131415161718192021# 系统内核[root@localhost /]# uname -r3.10.0-1127.el7.x86_64# 系统信息[root@localhost /]# cat /etc/os-releaseNAME=&quot;CentOS Linux&quot;VERSION=&quot;7 (Core)&quot;ID=&quot;centos&quot;ID_LIKE=&quot;rhel fedora&quot;VERSION_ID=&quot;7&quot;PRETTY_NAME=&quot;CentOS Linux 7 (Core)&quot;ANSI_COLOR=&quot;0;31&quot;CPE_NAME=&quot;cpe:/o:centos:centos:7&quot;HOME_URL=&quot;https://www.centos.org/&quot;BUG_REPORT_URL=&quot;https://bugs.centos.org/&quot;CENTOS_MANTISBT_PROJECT=&quot;CentOS-7&quot;CENTOS_MANTISBT_PROJECT_VERSION=&quot;7&quot;REDHAT_SUPPORT_PRODUCT=&quot;centos&quot;REDHAT_SUPPORT_PRODUCT_VERSION=&quot;7&quot; 安装 12345678910111213141516171819202122232425# 1.卸载旧版本yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine# 2.安装`yum-utils`软件包yum install -y yum-utils# 3.添加软件源yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 国外yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo #阿里云# 4.安装docker引擎和容器yum -y install docker-ce docker-ce-cli containerd.io# 5.启动dockersystemctl start docker# 6.查看docker版本 12# 7.运行hello-world测试docker run hello-world 1234# 8.查看镜像[root@localhost ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest bf756fb1ae65 8 months ago 13.3kB 卸载docker 1234# 卸载软件yum remove docker-ce docker-ce-cli containerd.io# 删除资源文件rm -rf /var/lib/docker 阿里云镜像加速 登录阿里云找到容器镜像服务 镜像加速器 123456789# 配置sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [&quot;https://a6gq0rdm.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 原理Docker是一个Client-Server结构的同，Docker的守护进程运行在主机上。通过Socket从客户端访问 Docker为什么比VM快？ Docker有着比虚拟机更少的抽象层 Docker利用的是宿主机内核，vm需要是Guest OS Docker常用命令 文档 帮助命令123docker version # 显示docker版本信息docker info # 显示docker系统信息docker --help # 帮助命令 镜像命令docker images 查看所有镜像 1234567891011121314[root@localhost etc]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhello-world latest bf756fb1ae65 8 months ago 13.3kB[root@localhost etc]# docker images --help# REPOSITORY 镜像的仓库源# TAG 镜像标签# IMAGE ID 镜像id# CREATED 镜像创建时间# SIZE 镜像大小# 可选项 -a，--all # 列出所有镜像 -q，--quiet # 只显示镜像id docker search 搜索镜像 1234567891011121314[root@localhost etc]# docker search mysqlNAME DESCRIPTION STARS OFFICIAL AUTOMATEDmysql MySQL is a widely used, open-source relation… 9934 [OK]mariadb MariaDB is a community-developed fork of MyS… 3634 [OK]mysql/mysql-server Optimized MySQL Server Docker images. Create… 724 [OK]percona Percona Server is a fork of the MySQL relati… 508 [OK]# 可选项[root@localhost etc]# docker search -h -f, --filter filter Filter output based on conditions provided --format string Pretty-print search using a Go template --limit int Max number of search results (default 25) --no-trunc Don&#x27;t truncate output docker pull下载镜像 12345678910111213141516171819202122232425262728293031323334353637383940# 下载镜像 docker pull 镜像名[:tag][root@localhost etc]# docker pull mysqlUsing default tag: latest # 默认最新latest: Pulling from library/mysqllatest: Pulling from library/mysqlbf5952930446: Pull complete # 分层下载，docker image的核心，联合文件系统8254623a9871: Pull complete938e3e06dac4: Pull completeea28ebf28884: Pull completef3cef38785c2: Pull complete894f9792565a: Pull complete1d8a57523420: Pull complete6c676912929f: Pull complete3cdd8ff735c9: Pull complete4c70cbe51682: Pull completee21cf0cb4dc3: Pull complete28c36cd3abcc: Pull completeDigest: sha256:6ded54eb1e5d048d8310321ba7b92587e9eadc83b519165b70bbe47e4046e76aStatus: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest #真实地址docker pull mysql == docker pull docker.io/library/mysql:latest# 指定版本下载[root@localhost etc]# docker pull mysql:5.75.7: Pulling from library/mysqlbf5952930446: Already exists8254623a9871: Already exists938e3e06dac4: Already existsea28ebf28884: Already existsf3cef38785c2: Already exists894f9792565a: Already exists1d8a57523420: Already exists5f09bf1d31c1: Pull complete1591b28581e8: Pull complete96ef942f7603: Pull complete2e009731422e: Pull completeDigest: sha256:1a83136153b238b659b0887ceb4e08275473af1eab2e67de4c22b37c5f4130cdStatus: Downloaded newer image for mysql:5.7docker.io/library/mysql:5.7 docker rmi删除镜像 12345678[root@localhost etc]# docker images -aREPOSITORY TAG IMAGE ID CREATED SIZEmysql 5.7 d589ea3123e0 2 days ago 448MBmysql latest 3646af3dc14a 2 days ago 544MBhello-world latest bf756fb1ae65 8 months ago 13.3kB[root@localhost etc]# docker rmi -f 3646af3dc14a 通过id删除[root@localhost etc]# docker rmi -f id id id 删除多个镜像[root@localhost etc]# docker rmi -f $(docker images -aq) 删除全部镜像 容器命令 有了镜像才可以创建容器，下载一个centos 1docker pull centos 新建容器并启动 1234567891011121314151617181920212223docker run [可选参数] image # 参数说明--name=&quot;Name&quot; 容器名字-d 后台方式运行-it 使用交互方式运行，进入容器查看内容-P 指定容器端口 8080:8080 -P 主机端口：容器端口 -P 容器端口 -P ip：主机端口：容器端口-p 随机指定端口# 测试## 启动并进入容器[root@localhost etc]# docker run -it centos /bin/bash[root@dc22cdc304ab /]# ls # 查看容器内的centosbin etc lib lost+found mnt proc run srv tmp vardev home lib64 media opt root sbin sys usr# 从容器中退出[root@115f580f95bd /]# exitexit[root@localhost /]# 列出所有的运行容器 123456789101112131415161718192021# docker ps #列出当前正在运行的容器-a # 列出当前正在运行的容器+历史运行过得容器-n=？ #显示最近创建的容器-q # 只显示容器编号[root@localhost /]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@localhost /]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS[root@localhost /]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES115f580f95bd centos &quot;/bin/bash&quot; 2 minutes ago Exited (0) 2 minut es ago amazing_vaughandc22cdc304ab centos &quot;/bin/bash&quot; 6 minutes ago Exited (0) 3 minut es ago unruffled_satoshi6831b24d8b06 bf756fb1ae65 &quot;/hello&quot; About an hour ago Exited (0) About a n hour ago zealous_blackburn[root@localhost /]# docker ps -a -n=1CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES115f580f95bd centos &quot;/bin/bash&quot; 3 minutes ago Exited (0) 3 minutes ago amazing_vaughan[root@localhost /]# docker ps -aq115f580f95bddc22cdc304ab6831b24d8b06 退出容器 12345678exit # 停止容器并退出Ctrl+P+Q # 容器不停止退出[root@9c647327935f /]# docker ps[root@localhost /]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9c647327935f centos &quot;/bin/bash&quot; 45 seconds ago Up 45 seconds nervous_elgamal[root@localhost /]# 删除容器 123docker rm 容器id #删除指定容器docker rm -f $(docker ps -ap) # 删除所有容器docker ps -a -q|xargs docker rm 启动和停止容器的操作 12345678910111213141516docker start 容器id # 启动容器docker restart 容器id #重启容器docker stop 容器id #停止容器docker kill 容器id #强制停止容器[root@localhost /]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES427a0b73db5e centos &quot;/bin/bash&quot; 48 seconds ago Exited (127) 35 seconds ago romantic_booth[root@localhost /]# docker start 427a0b73db5e427a0b73db5e[root@localhost /]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES427a0b73db5e centos &quot;/bin/bash&quot; About a minute ago Up 7 seconds romantic_booth[root@localhost /]# docker stop 427a0b73db5e427a0b73db5e 常用其他命令后台启动容器 12345678[root@localhost ~]# docker run -d centose42dc17c4ded0270fbdce2d0697804787986319854edbda5f2fe2bf49a184d35[root@localhost ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESe42dc17c4ded centos &quot;/bin/bash&quot; 43 seconds ago Exited (0) 24 seconds ago agitated_hoover427a0b73db5e centos &quot;/bin/bash&quot; 15 hours ago Exited (0) 15 hours ago romantic_booth# docker容器使用后台运行，就必须要一个前台进程，docker发现没有前台应用就会自动停止 查看日志 12[root@localhost ~]# docker logs -f -t --tail 10 e42dc17c4ded 10条日志 查看进程信息 1docker top 容器id 查看镜像元数据 1docker inspect 容器id 进入当前正在运行的容器 1234567# 我们通常都是使用后台方式启动运行的，需要进入容器，修改一些配置# 进入容器后开启新终端docker exec -it 容器id bashShell# 进入容器当前正在执行终端docker attach 容器id 拷贝容器内文件到主机上 123456# docker cp 容器id：容器内路径 目的主机路径[root@localhost ~]# docker cp e1b8972855ac:/22.java ./[root@localhost ~]# ls11.java 22.java anaconda-ks.cfg custom Docker练习安装Nginx123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# 1.docker search nginx 搜索镜像# 2.docker pull nginx 下载镜像[root@localhost ~]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginxlatest: Pulling from library/nginxbf5952930446: Pull completecb9a6de05e5a: Pull complete9513ea0afb93: Pull completeb49ea07d2e93: Pull completea5e4a503d449: Pull completeDigest: sha256:b0ad43f7ee5edbc0effbc14645ae7055e21bc1973aee5150745632a24a752661Status: Downloaded newer image for nginx:latestdocker.io/library/nginx:latest# 3 测试[root@localhost ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 4bb46517cac3 3 weeks ago 133MBcentos latest 0d120b6ccaa8 4 weeks ago 215MB# -d 后台启动 --name 给容器命名 -p宿主机端口：容器内部端口[root@localhost ~]# docker run -d --name nginx098 -p 3344:80 nginxbb9437232f7143a92dc3797b2535489d731b4e4882e53265001c39634089aa23[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbb9437232f71 nginx &quot;/docker-entrypoint.…&quot; 23 seconds ago Up 11 seconds 0.0.0.0:3344-&gt;80/tcp nginx098[root@localhost ~]# curl localhost:3344&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=&quot;http://nginx.org/&quot;&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=&quot;http://nginx.com/&quot;&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 安装Tomcat123456789# 官方docker run -it --rm tomcat:9.0 # 我们之前的启动都是后台，停止容器后还可以查到，docker run -it --rm 一般用来测试 用完即删的(删除容器不会删除镜像)# 正常启动docker run -d -p 8090:8080 --name tomcat1 tomcat# http://192.168.45.121:8090/测试访问没有问题# 进入容器 [root@localhost ~]# docker exec -it 61722710fb57 /bin/bash# linux命令少了，webapps里面没有文件，阿里云镜像的原因，剔除了不必要的东西，保证最小可运行环境 Portainer—Docker可视化12345docker run -d -p 9000:9000 \\ --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --name prtainer-test \\ docker.io/portainer/portainer 测试访问：http://192.168.45.121:9000/ Docker镜像是什么？Docker镜像加载原理docker镜像是有一层一层的文件系统组成，这种层级的文件系统叫联合文件系统（UnionFS） 分层1234567891011[root@localhost ~]# docker pull redis:5.0.95.0.9: Pulling from library/redisbf5952930446: Already exists # 已经存在的层911b8422b695: Pull complete093b947e0ade: Pull complete2e4ea19ac656: Pull complete62403d50d101: Pull complete3a097fa7018a: Pull completeDigest: sha256:ab3998e18bfaa570fad08c884ffbcc7861f59caf736a5a0c1ad5383c4d863958Status: Downloaded newer image for redis:5.0.9docker.io/library/redis:5.0.9 Docker镜像都是只读的，当容器启动时，一个新的可写层被加载到镜像的顶部 这一层就是容器层，容器之下的都叫镜像层 Commit镜像12docker commit 提交容器为一个新的副本docker commit -m=“message” -a=“author” 容器id 目标镜像名:[tag] 1如果想要保存当前的容器状态，就可以通过commit来提交。获得一个自己的镜像，好比快照 容器数据卷什么是容器数据卷容器之间可以有一个数据共享的技术，Docker容器中产生的数据，同步到本地 这就是卷技术！目录的挂载，将我们容器内的目录挂载到Linux上 容器的持久化和同步操作,容器间也是可以数据共享的 使用数据卷 方式一：直接使用命令来挂载 12345678910docker run -it -v 主机目录：容器目录[root@localhost ~]# docker run -it -v ~/custom:/home centos /bin/bash[root@77979c56cacc /]# lsbin dev etc home lib lib64 lost+found media mnt opt proc root run sbin srv sys tmp usr var[root@77979c56cacc /]# cd home/[root@77979c56cacc home]# lsredis-5.0.9.tar.gz# docker inspect 77979c56cacc查看信息 文件(目录)同步 好处：以后只需要在本地修改就可以同步到容器 安装MySQL12345678910111213 # 获取镜像docker pull mysql:5.7# 运行容器，挂载# 需要配置密码-d 后台运行-p 端口映射-v 卷挂载-e 环境配置--name 容器名字docker run -d -p3306:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql01 mysql:5.7#启动成功后在本地测试下 123456789101112131415# 在本地测试创建一个数据库，测试映射是否ok[root@localhost mysql]# ls data/auto.cnf ibdata1 private_key.pemca-key.pem ib_logfile0 public_key.pemca.pem ib_logfile1 server-cert.pemclient-cert.pem ibtmp1 server-key.pemclient-key.pem mysql sysib_buffer_pool performance_schema[root@localhost mysql]# ls data/auto.cnf ibdata1 private_key.pemca-key.pem ib_logfile0 public_key.pemca.pem ib_logfile1 server-cert.pemclient-cert.pem ibtmp1 server-key.pemclient-key.pem mysql sysib_buffer_pool performance_schema `test` 假设容器删除，挂载到本地的数据卷没有丢失，实现了容器数据持久化功能 具名挂载和匿名挂载123456789101112131415161718192021# 匿名挂载-v 容器内路径docker run -d -P --name nginx01 -v /etc/nginx nginx# 查看所有volume的情况[root@localhost ~]# docker volume lsDRIVER VOLUME NAMElocal 235cc62983d27076c03fd5b9511265b4092a518a2a5857e44168a55f7e4a2931local 436029b616a3b523f5b8563144c2afed69062547abc7dc5cafd46a9084b383c2# 这种就是匿名挂载#具名挂载[root@localhost ~]# docker run -d -P --name nginx02 -v juming-nginx:/etc/nginx nginx293c0e013dba80a42ff854b0ea5019a28233197f16ab12a1cd2230c517d321a1[root@localhost ~]# docker volume lsDRIVER VOLUME NAMElocal 235cc62983d27076c03fd5b9511265b4092a518a2a5857e44168a55f7e4a2931local 436029b616a3b523f5b8563144c2afed69062547abc7dc5cafd46a9084b383c2local juming-nginx# 通过 -v 卷名：容器内路径查看一下这个卷 所以的docker容器内的卷，没有指定目录的情况下都是在/var/lib/docker/volumes下 通过具名挂载可以方便找到卷 1234# 确定是具名挂载还是匿名挂载，还是指定路径挂载-v 容器内路径 # 匿名挂载-v 卷名：容器内路径 # 具名挂载-v /宿主机路径：容器内路径 # 指定路径挂载 初识DockerFileDockerfile 就是用来构建docker镜像的构建文件 通过这个脚本可以生成镜像，镜像是一层一层的，脚本是一个一个的命令 123456789101112# 创建一个dockerfile文件，名字可以随机# 文件中的指令都是大写，参数FROM centosVOLUME [&quot;volume01&quot;,&quot;volume02&quot;]CMD echo &quot;--------end----------&quot;CMD /bin/bash# 每个命令都是镜像的一层 1启动容器 这个卷外部一定有一个同步的目录（匿名挂载 ） 通过容器id查看一下 测试是否同步了 如果需要手动挂载镜像 -v 卷名：容器内路径 数据卷容器多个容器间实现数据共享 12345# 通过自己创建的镜像来创建三个容器docker run -it --name docker01 7fb29b29a668docker run -it --name docker02 --volumes-from docker01 7fb29b29a668docker run -it --name docker03 --volumes-from docker01 7fb29b29a668# 通过--volumes-from实现容器间共享 1# 测试删除docker01容器，docker02和03的数据还在 容器间配置信息的传递，数据卷容器的生命周期一直持续到容器没有使用为止。 DockerFiledockerfile是用来构建docker镜像的文件，命令参数脚本 构建步骤： 编写dockerfile文件 docker build构建镜像 docker run 运行镜像 docker push 发布 DockerFile构建过程基础知识： 每个保留关键字都是大写字母 执行从上到下顺序执行 #表示注释 每一个指令都会创建提交一个新的镜像层，并提交 Dockerimages：通过DockerFile构建生成的镜像，最终发布和运行的产品 DockerFile指令123456789101112FROM # 基础镜像，一切从这里开始构建MAINTAINER # 镜像是谁写的，姓名+邮箱RUN # 构建的时候需要运行的命令ADD # 步骤：tomcat镜像，这个tomcat压缩包，添加内容WOKRDIR # 镜像工作目录VOLUME # 挂载卷EXPOSE # 端口配置CMD # 指定容器启动时要运行的命令，会覆盖，只有最后一个会生效ENTRYPOINT # 指定容器启动时要运行的命令，不会覆盖，会追加ONBUILD # 当构建一个被继承COPY # 将文件拷贝到镜像中ENV # 构建的时候设置环境变量 DockerFile-centos 默认centos很多命令是没有的 自定义dockerfile并构建 可以看到我们配置的生效 还可以列出某个镜像的变更历史 CMD和ENTRYPOINT区别 测试CMD 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 编写dockerfile文件[root@localhost ~]# vim dockerfile-test-cmdFROM centosCMD [&quot;ls&quot;,&quot;-a&quot;]# 构建镜像[root@localhost ~]# docker build -f dockerfile-test-cmd -t cmdtest .Sending build context to Docker daemon 2.031MBStep 1/2 : FROM centos ---&gt; 0d120b6ccaa8Step 2/2 : CMD [&quot;ls&quot;,&quot;-a&quot;] ---&gt; [Warning] IPv4 forwarding is disabled. Networking will not work. ---&gt; Running in 8614ac972b4eRemoving intermediate container 8614ac972b4e ---&gt; a30c685ac1a8Successfully built a30c685ac1a8Successfully tagged cmdtest:latest# 运行 ls -a 生效[root@localhost ~]# docker run a30c685ac1a8WARNING: IPv4 forwarding is disabled. Networking will not work.....dockerenvbindevetchomeliblib64lost+foundmediamntoptprocrootrunsbinsrvsystmpusrvar# 想追加一个命令 -l ls -al[root@localhost ~]# docker run a30c685ac1a8 -lWARNING: IPv4 forwarding is disabled. Networking will not work.docker: Error response from daemon: OCI runtime create failed: container_linux.go:349: starting container process caused &quot;exec: \\&quot;-l\\&quot;: executable file not found in $PATH&quot;: unknown.# cmd指令下 -l 替换了CMD [&quot;ls&quot;,&quot;-a&quot;]命令，-l DockerFile制作tomcat1.准备tomcat和jdk压缩包 2.编写dockerfile文件，官方命名Dockerfile 1234567891011121314151617181920FROM centosMAINTAINER aurora&lt;23155203@qq.com&gt;COPY readme.txt /usr/local/readme.txtADD jdk-8u144-linux-x64.tar.gz /usr/local # ADD会自动解压ADD apache-tomcat-9.0.37.tar.gz /usr/localRUN yum -y install vimENV MYPATH /usr/local # 一进入就是此目录WORKDIR $MYPATHENV JAVA_HOME /usr/local/jdk1.8.0_144ENV CATALINA_HOME /usr/local/apache-tomcat-9.0.37ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/binEXPOSE 8080CMD /usr/local/apache-tomcat-9.0.37/bin/startup.sh &amp;&amp; tail -F /usr/local/apache-tomcat-9.0.37/bin/logs/catalina.out 3.构建镜像1docker build -t mytomcat . 4.运行容器1docker run -d -p 8081:8080 --name tomcat1 -v /home/aurora/build/tomcat/test:/usr/local/apache-tomcat-9.0.37/webapps/test -v /home/aurora/build/tomcat/logs/:/usr/local/apache-tomcat-9.0.37/logs c13b0d8d127c 5.发布项目测试 通过卷挂载 ，本地项目已经同步到容器了 日志信息也同步过来了 发布镜像1.登录阿里云找到容器镜像服务 2.创建命名空间 创建镜像仓库 3.阿里云教程 4.push Docker 网络Docker0 docker 是如何处理容器内网络访问的 123456789101112131415161718192021222324[root@aurora ~]# docker run -d -p 8080:8080 f796d3d2c195de57956557a2d041ed84f5344bd27ef36a0277bf02d16218873c6af4e3e056a9# 查看容器网络[root@aurora ~]# docker exec -it de57956557a2 ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever50: eth0@if51: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:12:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.18.0.2/16 brd 172.18.255.255 scope global eth0 valid_lft forever preferred_lft forever# Linux能ping通docker容器内部[root@aurora ~]# ping 172.18.0.2PING 172.18.0.2 (172.18.0.2) 56(84) bytes of data.64 bytes from 172.18.0.2: icmp_seq=1 ttl=64 time=0.096 ms64 bytes from 172.18.0.2: icmp_seq=2 ttl=64 time=0.089 ms64 bytes from 172.18.0.2: icmp_seq=3 ttl=64 time=0.083 ms64 bytes from 172.18.0.2: icmp_seq=4 ttl=64 time=0.080 ms 每运行一个docker容器，docker就会给容器分配一个ip，只要安装了docker，就会有一个网卡docker0，使用的是桥接模式，veth-pair技术 测试ip a 又多了一个网卡 在启动一个容器测试，发现又多了一个网卡 veth-pair 就是一对虚拟设备接口，他们都是成对出现的，一段连着协议，一段彼此相连 测试两个tomcat容器是否可以ping通 结果是可以的 所有的容器不指定网络的情况下，都是docker0路由的，docker会给容器分配可用ip Docker中的所有网络接口都是虚拟的，效率高 容器删除，对应网桥就没有了 –link123456789101112131415161718192021222324[root@aurora ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7e15416c5f39 f796d3d2c195 &quot;catalina.sh run&quot; 2 minutes ago Up 2 minutes 8080/tcp tom2abfa3e4a85a3 f796d3d2c195 &quot;catalina.sh run&quot; 2 minutes ago Up 2 minutes 8080/tcp tom1# 发现容器间无法通过名字ping通[root@aurora ~]# docker exec -it tom1 ping tom2ping: tom2: Name or service not known# --link 连接后可以通过名字ping[root@aurora ~]# docker run -d --name tom3 --link tom1 f796d3d2c195573a523b5bc039a830d64f7b3a55aa6a3e933e019d55a28b4c460f65108e215f[root@aurora ~]# docker exec -it tom3 ping tom1PING tom1 (172.18.0.2) 56(84) bytes of data.64 bytes from tom1 (172.18.0.2): icmp_seq=1 ttl=64 time=0.147 ms64 bytes from tom1 (172.18.0.2): icmp_seq=2 ttl=64 time=0.118 ms64 bytes from tom1 (172.18.0.2): icmp_seq=3 ttl=64 time=0.109 ms64 bytes from tom1 (172.18.0.2): icmp_seq=4 ttl=64 time=0.110 ms# 反向是无法ping通的[root@aurora ~]# docker exec -it tom1 ping tom3ping: tom3: Name or service not known 查看tom3的hosts配置 可以发现tom3的hosts里面对tom1的ip做了解析，我们可以通过名字或容器id来连通 但是在tom1里面并没有，所以就无法反向ping通。 现在不建议使用–link 自定义网络，不使用docker0 docker0 不支持容器名访问 自定义网络 查看所有docker网络 网络模式 bridge：桥接（默认） none：不配置网络 host：和宿主机共享网络 container：容器网络连通（局限性大） 测试 123456789101112131415161718192021docker run -d -P --name tom1 f796d3d2c195docker run -d -P --name tom1 --net bridge f796d3d2c195# 直接启动时，默认有--net bridge，就是docker0# docker0特点：默认，域名不能访问 --link 可以打通连接# 自定义网卡# --driver bridge# --subnet 192.168.0.0/16# --gateway 192.168.0.1[root@aurora ~]# docker network create --driver bridge --subnet 192.168.0.0/16 --gateway 192.168.0.1 aurora_net6d13d57495764d26aad369986410b3bab24bd1585bc24a319e35bf78401ab534[root@aurora ~]# docker network lsNETWORK ID NAME DRIVER SCOPE6d13d5749576 aurora_net bridge local839665245f94 bridge bridge localbd58428d04c0 host host locala544d905bb5c none null local 使用自定义网络启动两个tomcat测试 12docker run -d -P --name tom1-net --net aurora_net f796d3d2c195docker run -d -P --name tom2-net --net aurora_net f796d3d2c195 可以看到docker为两个容器分配了ip 再次测试ping连接 12345678910111213141516171819202122[root@aurora ~]# docker exec -it cc6a778c809f ping 192.168.0.2PING 192.168.0.2 (192.168.0.2) 56(84) bytes of data.64 bytes from 192.168.0.2: icmp_seq=1 ttl=64 time=0.156 ms64 bytes from 192.168.0.2: icmp_seq=2 ttl=64 time=0.100 ms^C--- 192.168.0.2 ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1000msrtt min/avg/max/mdev = 0.100/0.128/0.156/0.028 ms# 不使用--link就可以ping通名字了[root@aurora ~]# docker exec -it cc6a778c809f ping tom2-netPING tom2-net (192.168.0.3) 56(84) bytes of data.64 bytes from cc6a778c809f (192.168.0.3): icmp_seq=1 ttl=64 time=0.023 ms64 bytes from cc6a778c809f (192.168.0.3): icmp_seq=2 ttl=64 time=0.070 ms64 bytes from cc6a778c809f (192.168.0.3): icmp_seq=3 ttl=64 time=0.073 ms64 bytes from cc6a778c809f (192.168.0.3): icmp_seq=4 ttl=64 time=0.062 ms64 bytes from cc6a778c809f (192.168.0.3): icmp_seq=5 ttl=64 time=0.080 ms^C--- tom2-net ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 1002msrtt min/avg/max/mdev = 0.023/0.061/0.080/0.021 ms 好处：集群时不同的集群使用不同的网络，保证集群是安全的 网络连通 测试tom1连通到tom1-net 12345docker network connect aurora_net tom1docker network inspect aurora_net # 查看网卡情况# 发现docker直接把tom1加到aurora_net网卡了 查看tom1的ip 发现tom1有两个ip了 123456789101112# 连通ok[root@aurora ~]# docker exec -it 55909059da41 ping 46843aae707cPING 46843aae707c (192.168.0.2) 56(84) bytes of data.64 bytes from tom1-net.aurora_net (192.168.0.2): icmp_seq=1 ttl=64 time=0.072 ms64 bytes from tom1-net.aurora_net (192.168.0.2): icmp_seq=2 ttl=64 time=0.123 ms64 bytes from tom1-net.aurora_net (192.168.0.2): icmp_seq=3 ttl=64 time=0.095 ms^C--- 46843aae707c ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2msrtt min/avg/max/mdev = 0.072/0.096/0.123/0.023 ms 部署Redis集群SpringBoot微服务打包Docker镜像创建项目，编写controller Docker ComposeDocker Compose高效管理容器，定义运行多个容器","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.this52.cn/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"https://blog.this52.cn/tags/%E5%AE%B9%E5%99%A8/"}]},{"title":"JavaSPI机制","slug":"JavaSPI机制","date":"2020-06-12T16:00:00.000Z","updated":"2020-06-12T16:00:00.000Z","comments":true,"path":"posts/4dc5288/","link":"","permalink":"https://blog.this52.cn/posts/4dc5288/","excerpt":"","text":"JavaSPI机制SPI是什么？全成Service provider interface，中文意思是服务提供发现。它是JDK内置的一种服务提供发现机制 在微服务中也有服务发现，但是这两个并不是一个东西 Java SPI 实际上是“基于接口的编程＋策略模式＋配置文件”组合实现的动态加载机制 这就是典型的面向接口编程。 SPI实践（需要遵守SPI约定）JDK中提供了一个工具类java.util.ServiceLoader，查找服务实现。 可以看到他里面定义了一个常量PREFIX=&quot;META-INF/services/&quot;，它会根据这个前缀去查找jar包的META-INF/services/中的配置文件。配置文件中有接口的实现类全限定类名，可以根据类名进行加载实例化，就可以使用该服务了。 可以看到 Service模块 定义接口 12345package cn.this52.service;public interface PayService &#123; void pay();&#125; AliPay实现模块 定义实现类,引入Service jar，实现PayService接口 12345678910package cn.this52.service.impl;import cn.this52.service.PayService;public class AliPay implements PayService &#123; @Override public void pay() &#123; System.out.println(&quot;支付宝支付！&quot;); &#125;&#125; 12345&lt;dependency&gt; &lt;groupId&gt;cn.this52&lt;/groupId&gt; &lt;artifactId&gt;pay_service&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 在resources目录下创建META-INF/services文件夹，创建一个以接口全限定类名命名的文件,文件内容为实现类全限定类名 1cn.this52.service.impl.AliPay 测试模块 123456789101112131415package cn.this52.main;import cn.this52.service.PayService;import java.util.ServiceLoader;public class PayTest &#123; public static void main(String[] args) &#123; ServiceLoader&lt;PayService&gt; payServices = ServiceLoader.load(PayService.class); for (PayService payService : payServices) &#123; System.out.println(payService); payService.pay(); &#125; &#125;&#125; 成功调用到服务! SPI约定 当服务提供者提供了接口的一种具体实现后，在jar包的META-INF/services目录下创建一个以“接口全限定名”为命名的文件，内容为实现类的全限定名； 接口实现类所在的jar包放在主程序的classpath中； 主程序通过java.util.ServiceLoder动态装载实现模块，它通过扫描META-INF/services目录下的配置文件找到实现类的全限定名，把类加载到JVM； SPI的实现类必须携带一个不带参数的构造方法； SPI具体应用DriverManagerDriverManager是jdbc里管理和注册不同数据库driver的工具类。针对一个数据库，可能会存在着不同的数据库驱动实现。 Java定义了java.sql.Driver接口，并没有具体实现，都是由不同厂商来提供的 在JDBC4.0后连接数据库不需要再用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，就是使用了Java的SPI扩展机制来实现的 在mysql-connector-java 5.1.49jar中，META-INF/services目录下会有一个名字为java.sql.Driver的文件： 文件内容，跟我们刚刚实践的是一样的 12com.mysql.jdbc.Drivercom.mysql.fabric.jdbc.FabricMySQLDriver 看下Mysql Driver实现 可以看到它实现了java.sql.Driver接口，然后看下static静态块的DriverManage注册驱动 可以看到static静态块中有个loadInitialDrivers()方法 可以看到它使用的也是ServiceLoader类，遍历所有的jar下META-INF/services/中的以java.sql.Driver命名的文件里面的内容，并封装到一起，然后分割，通过Class.forName来加载类。就不需要我们来注册了。 Spring","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/categories/Java/"}],"tags":[{"name":"SPI","slug":"SPI","permalink":"https://blog.this52.cn/tags/SPI/"},{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/tags/Java/"}]},{"title":"SpringCloud随记","slug":"SpringCloud-Netflix","date":"2020-06-02T16:00:00.000Z","updated":"2020-06-02T16:00:00.000Z","comments":true,"path":"posts/f4bbff96/","link":"","permalink":"https://blog.this52.cn/posts/f4bbff96/","excerpt":"","text":"SpringCloud什么是微服务 微服务架构是一个分布式系统,按照业务划分成为不同的服务单元,解决单体系统性能不足等问题 微服务是一种架构风格,一个大型软件应用由多个服务单元组成,系统中的服务单元可以单独部署,各个服务单元之间是松耦合的 什么是SpringCloudSpringCloud是一种生态,是微服务系统架构的一站式解决方案,在我们构建微服务的过程中需要做如服务注册发现、配置中心、消息总线、负载均衡、断路器、数据监控等操作，SpringCloud为我们提供了一套方案，让我们在SpringBoot的基础上就能轻松的实现微服务项目的构建 SpringCloud和SpringBoot的关系 SpringBoot可以离开SpringCloud独立使用,但是SpringCloud离不开SpringBoot,依赖于它 SpringBoot专注于快速方便的开发单个个体微服务,SpringCloud关注全局的服务治理框架 微服务技术栈微服务开发作用: 快速开发服务 Spring SpringMvc SpringBoot 微服务注册与发现作用: 注册服务,发现服务,管理服务 Eureka Zookeeper ZooKeeper是用于维护配置信息，命名，提供分布式同步和提供组服务的集中式服务 Zookeeper 和 Eureka 区别 Zookeeper 保证 CP，Eureka 保证 AP： C：数据一致性； A：服务可用性； P：服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个。 微服务调用(协议) 通信协议 Rest 通过HTTP/HTTPS发送Rest请求进行数据交互 RPC 远程过程调用(Remote Procedure Call) Eureka注解: @EnableDiscoveryClient和@EnableEurekaClient共同点就是：都是能够让注册中心能够发现，扫描到改服务。 不同点：@EnableEurekaClient只适用于Eureka作为注册中心，@EnableDiscoveryClient 可以是其他注册中心。 1SpringCloud E版本后无需注解 配置文件详解以下配置都是以 eureka.server 开头： 参数 描述 备注 eureka.server.eviction-interval-timer-in-ms server清理无效节点的时间间隔 默认60秒 eureka.server.enable-self-preservation 是否开启自我保护，默认true true false eureka.server.renewal-percent-threshold 开启自我保护的系数 默认：0.85 client参数配置： 参数 描述 备注 eureka.client.enabled 是否开启client，默认true true false eureka.client.register-with-eureka 是否注册 默认true eureka.client.fetch-registry 是否检索服务 true false eureka.client.serviceUrl.defaultZone 默认服务注册中心地址 多个用”,”隔开 eureka.client.eureka-server-connect-timeout-seconds 连接server服务器超时时间 默认5秒 eureka.client.eureka-connection-idle-timeout-seconds 连接server的连接空闲时长 默认30秒 eureka.client.eureka-server-read-timeout-seconds 连接server读取数据超时时间 默认8秒 eureka.client.eureka-server-total-connections 连接server的最大连接数 默认200 eureka.client.eureka-server-total-connections-per-host 对单个server的最大连接数 默认50 eureka.client.eureka-service-url-poll-interval-seconds 获取集群中最新的server节点数据 默认0 eureka.client.heartbeat-executor-thread-pool-size client维持与server的心跳线程数 默认2 eureka.client.service-url 列出所有可用注册中心的地址 eureka instance 相关配置： 参数 描述 备注 eureka.instance.lease-renewal-interval-in-seconds 服务续约任务调用间隔时间，默认30秒 client每隔30秒向server上报自己状态，避免被server剔除 eureka.instance.lease-expiration-duration-in-seconds 服务时效时间，默认90秒 当server 90秒内没有收到client的注册信息时，会将该节点剔除 eureka.client.registry-fetch-interval-seconds client本地缓存清单更新间隔，默认30秒 client每隔30秒，向server请求可用服务清单。对于API网关类应用，可以适当降低时间间隔 eureka.instance.prefer-ip-address 注册服务时是否使用IP注册，默认false true false eureka.instance.ip-address server端的ip地址 eureka.instance.hostname server端的hostname 默认localhost eureka.instance.instance-id 注册到server的实例 RibbonFeignfeign是声明式的web service客户端,它让微服务之间的调用变得更简单了,SpringCloud集成了Ribbon和Eureka,可在Feign时提供负载均衡的http客户端 调用微服务两种方法 微服务名字ribbon 接口和注解feign 依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 定义接口,使用@FeignClient注解开启,绑定服务名 HystrixNetflix/Hystrix 在分布式环境中，不可避免地会有许多服务依赖项中的某些失败。 Hystrix旨在执行以下操作： 提供保护并控制延迟和失败，以及通过第三方客户端库（通常是通过网络）访问的依赖项的失败。 停止复杂的分布式系统中的级联故障。 快速失败，迅速恢复。 回退并在可能的情况下正常降级。 启用近乎实时的监视，警报和操作控制。 服务熔断 服务降级一般是某个服务故障或者是异常引起的，类似现实世界中的 保险丝 ，当某个异常条件被触发，直接熔断整个服务，而不是一直等待，直到此服务超时。 实现类实现FallbackFactory接口,返回一个接口的实现类,在服务接口中指定实现类 还需要在yaml配置中开启服务降级 123feign: hystrix: enabled: true 服务熔断和服务降级总结相同点 目的很一致，都是从可用性可靠性着想，为防止系统的整体缓慢甚至崩溃，采用的技术手段； 最终表现类似，对于两者来说，最终让用户体验到的是某些功能暂时不可达或不可用； 粒度一般都是服务级别，当然，业界也有不少更细粒度的做法，比如做到数据持久层（允许查询，不允许增删改） 自治性要求很高，熔断模式一般都是服务基于策略的自动触发，降级虽说可人工干预，但在微服务架构下，完全靠人显然不可能，开关预置、配置中心都是必要手段 ； 不同点 触发原因不太一样：服务降级一般是从 整体负荷考虑；服务熔断一般是 某个服务（下游服务）故障引起 ； 管理目标的层次不太一样：降级一般需要对业务有层级之分（核心业务，非核心业务）；熔断 其实是一个框架级的处理，每个微服务都需要（无层级之分 Zuul路由网关 在启动类上添加@EnableZuulProxy注解 pom12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-zuul&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; SpringCloud ConfigSpring Cloud Config为分布式系统中的外部化配置提供服务器端和客户端支持。使用Config Server，您可以在中心位置管理所有环境中应用程序的外部属性。客户端和服务器上的概念都与Spring Environment和PropertySource抽象映射相同，因此它们非常适合Spring应用程序，但可以与以任何语言运行的任何应用程序一起使用。在应用程序从开发人员到测试人员再到生产人员的整个部署过程中，您可以管理这些环境之间的配置，并确保应用程序具有它们迁移时所需的一切。服务器存储后端的默认实现使用git，因此它轻松支持带标签的配置环境版本，并且可以通过各种工具来访问这些内容来管理内容。添加替代实现并将其插入Spring配置很容易 HTTP服务具有以下形式的资源： 12345&#x2F;&#123;application&#125;&#x2F;&#123;profile&#125;[&#x2F;&#123;label&#125;]&#x2F;&#123;application&#125;-&#123;profile&#125;.yml&#x2F;&#123;label&#125;&#x2F;&#123;application&#125;-&#123;profile&#125;.yml&#x2F;&#123;application&#125;-&#123;profile&#125;.properties&#x2F;&#123;label&#125;&#x2F;&#123;application&#125;-&#123;profile&#125;.properties application在SpringApplication中作为spring.config.name注入（在常规Spring Boot应用中通常是application），profile是有效配置文件（或逗号分隔）属性列表），而label是可选的git标签（默认为master。） Server 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 123456789101112server: port: 8888spring: application: name: springcloud-config-server # 从git获取配置 cloud: config: server: git: uri: https://gitee.com/aurora5/springcloud-config.git 在启动类上使用注解@EnableConfigServer开启 Client 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; 1 常见错误以及解决方案 java.lang.NoClassDefFoundError: org/springframework/boot/bind/RelaxedPropertyResolver 因为Druid中默认使用的SpringBoot版本是1.5.12,这个版本中引入了RelaxedPropertyResolver 在pom.xml中添加 12345&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.8.RELEASE&lt;/version&gt;&lt;/parent&gt; 覆盖掉druid-spring-boot-starter中的springboot版本，解决 Field deptMapper in cn.this52.springcloud.service.DeptServiceImpl required a bean of type &#39;cn.this52.springcloud.mapper.DeptMapper&#39; that could not be found. 找不到Mapper接口 解决方案: 在Mapper接口上添加@Mapper注解 在启动类或者其他配置类上添加@MapperScan注解扫描Mapper对应的包 ​","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.this52.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.this52.cn/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.this52.cn/tags/SpringCloud/"}]},{"title":"SpringBoot随记","slug":"SpringBoot随记","date":"2020-05-21T16:00:00.000Z","updated":"2020-05-21T16:00:00.000Z","comments":true,"path":"posts/7a37d93e/","link":"","permalink":"https://blog.this52.cn/posts/7a37d93e/","excerpt":"","text":"SpringBoot开始延迟初始化bean不会一开始就初始化，启动快，但是相应的bean配置错误不会在一开始显现出来 123spring: main: lazy-initialization: true 元数据支持引入configuration-processor依赖，在yaml中配置也会有相应提示 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 会生成metadata.json 配置属性Javabean属性绑定和Constructor绑定 yaml 1234567acme: enabled: false remote-address: 192.168.45.113 security: username: root password: root roles: [11,22,33] 松散绑定了解一下 JSR-303属性校验 如果存在内部类，在内部类加上@Valid注解才会生效 @ConfigurationProperties vs. @Value 特征 @ConfigurationProperties @Value 松散绑定 Yes Limited (see note below)有限支持 元数据支持 Yes No SpEL 表达式 No Yes 复杂类型绑定 Yes No JSR-303属性校验 Yes No Async12345678910111213@Servicepublic class AsyncService &#123; @Async // 异步任务 public void hello()&#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;数据处理完成！&quot;); &#125;&#125; 12345678910111213@Controllerpublic class AsyncController &#123; @Autowired private AsyncService asyncService; @ResponseBody @GetMapping(&quot;hello&quot;) public String hello() &#123; asyncService.hello(); return &quot;OK&quot;; &#125;&#125; 123456789@EnableAsync // 开启异步功能@SpringBootApplicationpublic class SpringbootAsyncMailScheduledApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootAsyncMailScheduledApplication.class, args); &#125;&#125; Schedule123456789@Servicepublic class ScheduledService &#123; // 定时任务 cron表达式（5秒执行一次） @Scheduled(cron = &quot;0/5 * * * * *&quot;) public void printDate()&#123; System.out.println(new Date()); &#125;&#125; 123456789@EnableScheduling // 开启定时任务@SpringBootApplicationpublic class SpringbootAsyncMailScheduledApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootAsyncMailScheduledApplication.class, args); &#125;&#125; Mail","categories":[{"name":"Spring","slug":"Spring","permalink":"https://blog.this52.cn/categories/Spring/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/tags/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.this52.cn/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.this52.cn/tags/SpringBoot/"}]},{"title":"Linux随记","slug":"Linux","date":"2020-05-14T16:00:00.000Z","updated":"2020-05-14T16:00:00.000Z","comments":true,"path":"posts/76623e95/","link":"","permalink":"https://blog.this52.cn/posts/76623e95/","excerpt":"","text":"Centos7基本命令12345678910111213141516who 登录日志who am i 当前登录用户ifconfig 查看ip地址clear 清屏sed -n &#x27;5,10p&#x27; filename 查看指定文件5到10行rpm 安装 rpm -ivh * 安装某软件(ivh显示安装进度)tar 解压 tar -zxvf * 使用gz解压显示进度ps -ef 查看进程 ps -ef | grep redis 查看redis的进程systemctl status/stop/disable firewalld.service 防火墙 网络配置12345678910111213141516171819202122# vi /etc/sysconfig/network-scripts/ifcfg-ens33[root@localhost network-scripts]# cat ifcfg-ens33TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;BOOTPROTO=&quot;dhcp&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot;UUID=&quot;6d1accaa-7419-498a-9551-a473c183b8f4&quot;DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot;IPADDR=&quot;192.168.45.128&quot;PREFIX=&quot;24&quot;GATEWAY=&quot;192.168.45.2&quot;IPV6_PRIVACY=&quot;no&quot; 常用配置Jdk1.81.解压 1tar -zxvf jdk-8u144-linux-x64.tar.gz # 这里指定解压到哪里 2.环境配置 在.bash_profile或者/etc/profile中配置 12export JAVA_HOME=/root/envs/jdk1.8.0_144export PATH=$JAVA_HOME/bin:$PATH 执行source .bash_profile使环境变量生效 Tomcat 9.0.37解压安装即可 Nginx安装 首先安装zlib-devel-1.2.7-17.el7.x86_64.rpm 解压pcre-8.38.tar.gz 1tar -zxvf pcre-8.38.tar.gz -C /www/server 安装pcre-8.38.tar.gz 123cd ~/envs/pcre-8.38/./configuremake &amp;&amp; make install 解压 安装 123cd ~/envs/nginx-1.15.6/ ./configuremake &amp;&amp; make install 跟上面一样 启动Nginx 12cd &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;.&#x2F;nginx 启动成功 测试：http://192.168.45.111/ 反向代理&amp;&amp;负载均衡（Load Balance）12cd /usr/local/nginx/confvi nginx.conf 配置示例 1234567891011121314151617181920212223242526272829303132333435#1upstream local.this52.cn&#123; server 192.168.45.112:8080; server 192.168.45.113:8080;&#125; server &#123; listen 80; server_name localhost; #基于反向代理访问tomcat服务器 location / &#123; proxy_pass http://local.this52.cn; &#125; &#125; #2upstream tomcatserver &#123; server 192.168.45.122:8080 ; server 192.168.45.123:8080 ;&#125; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; # root html; # index index.html index.htm; # proxy_pass http://tomcatserver; &#125; location路径映射1234# 1. 精准匹配location =/ &#123; #精准匹配&#125; 1234# 2.通用匹配location / &#123; # 匹配所有以/开头的路径&#125; 1234567# 2.正则匹配location ~ /xx &#123; # 匹配所有以/xx开头的路径(区分大小写)&#125;location ~* /xx&#123; # 匹配所有以/xx开头的路径(不区分大小写)&#125; 动静分离动态资源代理123location / &#123; proxy_pass 路径;&#125; 静态资源代理 12345678location / &#123; root 静态资源路径; index 默认访问路径下的资源; autoindex on; # 开启目录浏览(索引) autoindex_exact_size off; # 显示文件大小 autoindex_localtime on; # 显示时间 charset utf-8; # 解决中文乱码&#125; 集群 解决单点故障，避免nginx宕机 使用keepalived监听nginx状况 使用haproxy，提供虚拟路径，接受用户请求 yum源123sudo rpm -ivh http://nginx.org/packages/centos/7/noarch/RPMS/nginx-release-centos-7-0.el7.ngx.noarch.rpmsudo yum install nginx set_header123456proxy_pass http://abc.com;proxy_set_header Host $host;#保留代理之前的hostproxy_set_header X-Real-IP $remote_addr;#保留代理之前的真实客户端ipproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header HTTP_X_FORWARDED_FOR $remote_addr;#在多级代理的情况下，记录每次代理之前的客户端真实ipproxy_redirect default;#指定修改被代理服务器返回的响应头中的location头域跟refresh头域数值 反向代理静态资源4041234# 单独处理location ~ .*\\.(js|css)$ &#123; proxy_pass http:&#x2F;&#x2F;149.28.31.159:65432;&#125; 问题1234567# nginx转发请求异常的解决办法 failed (13: Permission denied) while connecting to upstream# 两种方法1. 开启httpd网络连接 执行 setsebool httpd_can_network_connect=1 (重启后失效) setsebool -P httpd_can_network_connect 1 (重启后保留)2. 修改nginx.conf中user nginx为 user root MySQL5.7安装(基于Centos7)1.安装Yum Repo12345678# 下载wget https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm# 安装yum源yum localinstall -y mysql57-community-release-el7-9.noarch.rpm# 或者yum localinstall -y https://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm 检查yum源是否安装成功 1yum repolist enabled | grep &quot;mysql.*-community.*&quot; 2.安装MySQL12345678yum install -y mysql-community-server# 启动systemctl start mysqld# 开机自启systemctl enable mysqld# 查看状态 查看密码 1grep &#x27;temporary password&#x27; /var/log/mysqld.log 登录mysql -uroot -pqLqMjAj3q2-J 修改密码 123456mysql&gt; ALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;root&#39;;ERROR 1819 (HY000): Your password does not satisfy the current policy requirements# 默认不能设置简单密码，更改全局策略set global validate_password_policy&#x3D;0;set global validate_password_length&#x3D;1; 3.其他配置12345678# 配置字符集编辑&#x2F;etc&#x2F;my.cnf，在[mysqld]配置character-set-server&#x3D;utf8# 开启远程控制grant all privileges on *.* to root@&quot;root&quot; identified by &quot;root&quot;;flush privileges; #刷新 5.卸载MySQL123456789101112131415rpm -qa |grep -i mysql # 查看mysql安装的依赖# 卸载yum remove mysql...# 查找mysql相关目录find / -name mysql# 删除rm -rf# 删除/etc/my.cnfrm -rf /etc/my.cnf# 删除/var/log/mysqld.logrm -rf /var/log/mysqld.log MySql5.7主从复制(基于Docker)1.安装这里使用Docker创建三个个mysql容器 架构划分 192.168.56.10:3306 master节点 192.168.56.10:3307 slave节点 192.168.56.10:3308 slave节点 1234567891011# 拉取镜像docker pull mysql:5.7# 创建两个mysql容器并挂载配置文件以及数据以及设置环境#masterdocker run -d -p3306:3306 -v /home/mysql/master-conf:/etc/mysql/conf.d -v /home/mysql/master-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql-master ef08065b0a30#slave1docker run -d -p3307:3306 -v /home/mysql/slave1-conf:/etc/mysql/conf.d -v /home/mysql/slave1-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql-slave1 ef08065b0a30#slave2docker run -d -p3308:3306 -v /home/mysql/slave2-conf:/etc/mysql/conf.d -v /home/mysql/slave2-data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=root --name mysql-slave2 ef08065b0a30 容器ok，卷挂载ok 2.测试连接连接ok！ 3.配置1234567891011121314151617#mastervim master-conf/my.cnf[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql#log-error = /var/log/mysql/error.log# By default we only accept connections from localhost#bind-address = 127.0.0.1# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0server-id=1 #唯一标识log-bin=mysql-bin #日志名log-slave-updates #日志变化时从节点自动更新slave-skip-errors=all #跳过错误日志 1234567891011121314151617#slave1vim slave1-conf/my.cnf[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql#log-error = /var/log/mysql/error.log# By default we only accept connections from localhost#bind-address = 127.0.0.1# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0server-id=2log-bin=mysql-binlog-slave-updatesslave-skip-errors=all 1234567891011121314151617#slave2vim slave1-conf/my.cnf[mysqld]pid-file = /var/run/mysqld/mysqld.pidsocket = /var/run/mysqld/mysqld.sockdatadir = /var/lib/mysql#log-error = /var/log/mysql/error.log# By default we only accept connections from localhost#bind-address = 127.0.0.1# Disabling symbolic-links is recommended to prevent assorted security riskssymbolic-links=0server-id=3log-bin=mysql-binlog-slave-updatesslave-skip-errors=all 重启mysql容器 1docker restart CONTAINER_ID 查看配置是否生效 1SHOW VARIABLES like &#x27;server_id&#x27;; slave节点也都ok 登录master查看状态 1show master status; 登录slave节点设置对应master 123456change master to master_host=&#x27;172.17.0.4&#x27;,master_user=&#x27;root&#x27;,master_password=&#x27;root&#x27;,master_log_file=&#x27;mysql-bin.000001&#x27;,master_log_pos=154; 开启/关闭从节点 1start/stop slave; 登录slave查看状态 123456789101112131415mysql&gt; show slave status\\G; # 加上\\G可以格式化查看*************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.17.0.4 Master_User: root Master_Port: 3306 Connect_Retry: 60 Master_Log_File: mysql-bin.000001 Read_Master_Log_Pos: 154 Relay_Log_File: 3fb4da57e759-relay-bin.000004 Relay_Log_Pos: 320 Relay_Master_Log_File: mysql-bin.000001 Slave_IO_Running: Yes Slave_SQL_Running: Yes 4.测试主从复制master创建表和数据库后slave节点都同步过去了 MySql读写分离","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/categories/Linux/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/tags/Linux/"}]},{"title":"jsDelivr-Github+PicGo打造免费高效的图床","slug":"jsDelivr-Github-PicGo打造免费高效的图床","date":"2020-05-07T15:22:49.000Z","updated":"2020-05-07T15:22:49.000Z","comments":true,"path":"posts/9eb07c63/","link":"","permalink":"https://blog.this52.cn/posts/9eb07c63/","excerpt":"","text":"前言 jsDelivr：免费的开源CDN，白嫖党的福音 Github:最大的同性交友网站 PicGo:一个用于快速上传图片并获取图片URL链接的工具 创建Github图床 首先需要注册一个Github账号 新建一个仓库 生成Token Node随意，勾选repo，最后Generate token，然后会生成一个token，这个token后面需要用到，且只会出现一次，保存好 配置PicGo+jsDelivr 下载PicGo,选择对应的版本 配置图床 分支名：写master就ok 储存路径：没有文件夹就写/,建议创建文件夹，路径就是xxx/ 自定义域名的作用是在上传图片后成功后，PicGo会将“自定义域名+上传的图片名”生成的访问链接 我们这里就可以使用jsDelivr来加速了 自定义域名规则：https://cdn.jsdelivr.net/gh/+用户名/仓库名 最后 jsDelivr实在是太香了 我们这里是直接引用，其实还有很多用法，比如通过版本号来引用，通过分支引用，都会有不同的缓存效果。一般都是缓存一天 友情提示：一个仓库放的图片不要超过1G，否则可能会封号","categories":[],"tags":[{"name":"jsDelivr","slug":"jsDelivr","permalink":"https://blog.this52.cn/tags/jsDelivr/"},{"name":"GitHub","slug":"GitHub","permalink":"https://blog.this52.cn/tags/GitHub/"},{"name":"PicGo","slug":"PicGo","permalink":"https://blog.this52.cn/tags/PicGo/"},{"name":"图床","slug":"图床","permalink":"https://blog.this52.cn/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"CDN","slug":"CDN","permalink":"https://blog.this52.cn/tags/CDN/"}]},{"title":"Ngrok实现内网穿透","slug":"Ngrok实现内网穿透","date":"2020-04-22T14:05:41.000Z","updated":"2020-04-22T14:05:41.000Z","comments":true,"path":"posts/bf37a4ea/","link":"","permalink":"https://blog.this52.cn/posts/bf37a4ea/","excerpt":"","text":"什么是Ngrok？ ngrok 是一个反向代理，通过在公共的端点和本地运行的 Web 服务器之间建立一个安全的通道。我们可以使用它来实现内网穿透，让外网访问内网服务器不再是距离 什么是内网穿透？为什么需要内网穿透? 内网穿透即NAT穿透，通过端口映射将一台主机的内网(LAN)IP地址映射成一个公网(WAN)IP地址，让互联网上的用户可以通过此公网IP地址访问特定的内网主机所提供的网站或者服务器 简单点来说，就是别人访问到我们本地部署的项目,在外网演示内网web站点 本次教程就以Hexo博客作为演示 首先我们进入Ngrok平台，没有账号的需要注册一个 点击隧道管理，开通隧道 选择服务器，我们这里使用免费的服务器 选择http协议，隧道名称自定义，前置域名自定义，本地端口选择对应的，我们这里演示的hexo的端口是4000，确认添加然后开通就ok了 下载合适的客户端 启动hexo服务 在Ngrok目录找到bat启动工具，启动，然后去Ngrok后台隧道管理里面复制隧道id 部署完成，我们就可以通过外网访问我们本地的web服务了","categories":[],"tags":[{"name":"Ngrok","slug":"Ngrok","permalink":"https://blog.this52.cn/tags/Ngrok/"}]},{"title":"为什么说重写equals方法就一定要重写hashCode方法?","slug":"为什么说重写equals方法就一定要重写hashCode方法","date":"2020-04-16T12:18:08.000Z","updated":"2020-04-16T12:18:08.000Z","comments":true,"path":"posts/440fe77e/","link":"","permalink":"https://blog.this52.cn/posts/440fe77e/","excerpt":"","text":"前言 很多人可能都知道==和equals的区别，但是很多人不知道为什么重写equals就要重写hashCode，我们先来看一下==与equals的区别 ==与equals==如果比较的是两个基本数据类型，那么 == 比较的是值；如果是两个非基本数据类型的对象，那就是判断它们的内存地址是不是相同； equals 如果类没有覆盖 equals 方法，那么 equals 等价于 == ； 如果覆盖了 equals 方法，那么就需要根据 equals 方法的逻辑来判断两个对象是否相等。 我们可以看下经常用到的String内部的equals方法 我们可以看到它会先比较内存地址，如果不相等才会去比较内容 正确使用equals方法我们在使用 equals 方法的时候，容易发生空指针异常，所以在使用前需要判断对象是否为 null，或者用常量来调用 equals： 12if(string != null &amp;&amp; string.equals(&quot;Aurora&quot;))&#123;&#125;if(&quot;Aurora&quot;.equals(string))&#123;&#125; java.util.Objects 中还给我们提供了一个 equals 方法： 从这个方法的源码中可以看出，方法已经帮我们考虑到null值的问题了，所以可以放心使用 1Objects.equals(string, &quot;Aurora&quot;); 覆盖 equals 方法的准则 自反性：对于任何非空引用值 A，A.equals(A) 返回 true。 对称性：对于任何非空引用值 A 和 B，A.equals(B) 和 B.equals(A) 的结果相同。 传递性：对于任何非空引用值 A、B 和 C，如果 A.equals(B) 返回 true， A.equals(C) 返回 true，那么 B.equals(C) 也是 true。 一致性：对于任何非空引用值 A 和 B，每一次调用 x.equals(y) 的结果是相同的。 非空性：对于任何非空引用值 A，A.equals(null) 应返回 false。 equals() 与 hashCode()hashCode() 方法是获取 hash 码（哈希码、散列码），返回一个 int 整数；hash 码的作用是确定对象在散列结构中的位置。 hashCode() 方法存在于 Object 类中，代表 Java 中的任何类都会有 hashCode() 方法，那么任何场景下 hashCode() 都会产生作用么？其实并不是！ 如果对象会被放入散列结构中使用，那么 hashCode() 就会起作用。 比如，当我们要向 HashMap 中放入一组 key-value 的时候，那么 HashMap 会先根据 key 对象的 hashCode 值判断存入的位置，如果 key 存入的位置上已经有了一个元素，再根据 equals() 方法判断两个元素是否相等；如果确认相等，那么会覆盖原来的 key-value 。 123456789final V putVal(...)&#123; ... if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; ...&#125; 这时候，equals() 与 hashCode() 就是有关系的： 两个对象 equals() 返回 true 的时候，那它们的 hashCode() 值需要相等； 如果两个对象的 hashCode() 值相等，那它们 equals() 不一定是 true；（哈希冲突） 所以在这种情况下，如果要判断两个对象是否相等，除了要覆盖 equals() ，也要覆盖 hashCode()，否则就会发生意料之外的问题。 当然，如果对象不会放入散列表中使用，那么 equals() 与 hashCode() 其实也没啥关系。","categories":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/tags/Java/"}]},{"title":"Hexo之URL优化","slug":"Hexo之URL优化","date":"2020-03-19T06:45:04.000Z","updated":"2020-03-19T06:45:04.000Z","comments":true,"path":"posts/ec6298cf/","link":"","permalink":"https://blog.this52.cn/posts/ec6298cf/","excerpt":"","text":"Hexo的默认URL格式是日期加标题，permalink: :year/:month/:day/:title/，这种格式有很多缺点： 缺点一：url过长 缺点二：年月日都有分隔符，url层级过多 缺点三：如果标题是中文，url会自动被编码，就会造成所谓的乱码现象，导致url过长 不好看也不利于seo hexo-abbrlink插件 进入Hexo博客根目录,安装插件 1npm install hexo-abbrlink --save 修改hexo的配置文件_config.yml中的permalink 1permalink: article/:abbrlink/ 在下面加上 123456789abbrlink: alg: crc16 #support crc16(default) and crc32 rep: hex #support dec(default) and hex drafts: false #(true)Process draft,(false)Do not process draft # Generate categories from directory-tree # depth: the max_depth of directory-tree you want to generate, should &gt; 0 auto_category: enable: false depth: alg&amp;rep的配置 12345678910crc16 &amp; hexhttps://post.zz173.com/posts/66c8.htmlcrc16 &amp; dechttps://post.zz173.com/posts/65535.htmlcrc32 &amp; hexhttps://post.zz173.com/posts/8ddf18fb.htmlcrc32 &amp; dechttps://post.zz173.com/posts/1690090958.html 局限性：crc16的最大帖子数是65535，但是对于大部分人也够用了 最后链接就是这样的","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://blog.this52.cn/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://blog.this52.cn/tags/Hexo/"},{"name":"URL","slug":"URL","permalink":"https://blog.this52.cn/tags/URL/"}]},{"title":"Hexo搭建及部署","slug":"Hexo搭建及部署","date":"2020-03-12T03:13:06.000Z","updated":"2020-09-28T15:40:42.000Z","comments":true,"path":"posts/43ca43ae/","link":"","permalink":"https://blog.this52.cn/posts/43ca43ae/","excerpt":"","text":"本教程基于win10，其他系统自测！ Hexo简介 Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以生成静态页面托管在github和coding上，是搭建博客的首选框架。大家可以进入Hexo官网进行详细的查看。 第一部分安装Node.js Download 选择合适的版本（建议至少为Node.js 8.10） 然后一路next即可 安装好后用node -v和npm -v查看一下版本（有版本一般就没啥问题了） 安装Git Download 一路傻瓜式安装 最后用git --version来查看下版本 之后的命令都可以基于git bash进行，安装途中出现WARN可以无视 没有梯子的建议使用国内镜像加速npm install -g cnpm --registry=https://registry.npm.taobao.org 如果更换国内源后续命令使用cnpm 没有就使用npm 安装Hexo 完成上面的要求后 我们就可以使用npm命令安装Hexo了 1npm install -g hexo-cli 依旧用hexo -v检查一下版本 hexo安装完成 接下来进入到主题 随意位置创建一个文件夹 1mkdir blog &#x2F;&#x2F;名字随意 后续所有文件都在这个文件夹 命令行进入这个目录 1cd blog 初始化hexo 1hexo init 现在博客文件已经初始化完成 12345678项目目录结构├── _config.yml # hexo的配置信息，你可以在此配置大部分的参数。├── package.json #应用程序数据├── scaffolds #模板资源文件夹├── source #资源文件夹| ├── _drafts #草稿文件夹| └── _posts # markdown页面文件└── themes #主题文件夹 接下来输入npm install安装所有依赖。 最后我们可以运行命令部署博客 1hexo s 此时即可使用浏览器访问 http://localhost:4000，检查站点是否正确运行。 这是我本地预览效果的，换过主题的，默认的比较纯净哈哈 常用命令 hexo clean 清理缓存文件和生成的文件 hexo g 生成静态文件（hexo genrate缩写 ） hexo s 启动本地服务器（hexo server缩写） hexo d 部署（hexo deploy缩写） ctrl+c关闭本地服务器。 第二部分部署到github上面 在GitHub上面注册一个账号 新建一个仓库，仓库名规则**github用户名.github.io**。这个很重要!!!! 打开git bash 设置SSH远程连接 设置Git的username和email,根据自己实际的填写 12git config --global user.name &quot;username&quot;git config --global user.email &quot;email&quot; 然后密钥SSH key 1ssh-keygen -t rsa -C &quot;email&quot; 回车三下,会生成两个文件id_rsa和id_rsa.pub 打开github-&gt;点头像-&gt;settings-&gt;SSH and GPG keys 新建一个SSH，把id_rsa.pub内容复制到SSH的key里面 打开博客根目录下的_config.yml文件，也就是博客的配置文件 修改depoly配置 repo配置,复制SSH克隆地址 1234deploy: type: git repo: git@github.com:&#x2F;52assert&#x2F;52assert.github.io.git branch: master 安装一个插件npm install --save hexo-deployer-git 最后运行命令hexo d就可以提交内容到github上了，然后通过github名.github.io来访问 部署到远程服务器服务器配置（Centos为例） 安装宝塔面板 升级Centos所有包，包括系统版本内核升级 1yum -y update 安装git 1yum install -y git 安装Nginx（这里演示宝塔操作） 添加站点 Git配置 创建文件目录，用于私人Git仓库搭建 ​ 6.1 在www目录下新建目录GitConfig，给755权限 ​ 6.2 Git初始化 1cd /www/GitConfig 1git init --bare hexo.git ​ 6.3 创建Git钩子（hook） 进入/www/GitConfig/hexo.git/hooks 目录 新建一个文件post-receive 编辑文件指定Git的源代码和Git配置文件 12#!/bin/bashgit --work-tree=/www/wwwroot/blog.this52.cn --git-dir=/www/GitConfig/hexo.git checkout -f 命令中的work-tree是网站目录 然后保存退出，给755权限 本地配置 进入Hexo根目录，修改站点配置文件_config.yml 修改repo repo：root@ip:/www/GitConfig/hexo.git 执行命令，部署到服务器上 1hexo clean &amp;&amp; hexo g -d 部署到服务器的时候需要输入服务器密码 最后讲下简单使用_config.yml配置Site 设置 描述 title 网站的标题 subtitle 网站的字幕 description 网站说明 keywords 网站关键字,用逗号分隔多个关键字。 author 你的名字 language 网站的语言。默认值为en。 URL 设置 描述 url 您网站的网址 添加标签页面 前往Hexo博客根目录,执行命令 1hexo new page tages 找到source/tags/index.md这个文件 修改这个文件 12345---title: 标签date: 2020-06-28 00:00:00type: &quot;tags&quot;--- 添加分类页面 前往Hexo博客根目录,执行命令 1hexo new page categories 找到source/categories/index.md这个文件 修改文件 12345---title: 分类date: 2020-06-28 00:00:00type: &quot;categories&quot;--- 添加友情链接页面 前往Hexo博客根目录,执行命令 1hexo new page link 找到source/link/index.md这个文件 修改文件 12345---title: 友情链接date: 2020-06-28 00:00:00type: &quot;link&quot;--- 添加友情链接在hexo博客目录中的source/_data,创建一个link.yml文件 123456789101112131415161718192021222324252627- class_name: 友情鏈接 class_desc: 那些人，那些事 link_list: - name: Aurora link: https://blog.this52.cn/ avatar: https://cdn.jsdelivr.net/gh/52assert/CDN/img/20200628150416.jpg descr: 偷偷厉害 万物尽可期待！ - name: Hexo link: https://hexo.io/zh-tw/ avatar: https://d33wubrfki0l68.cloudfront.net/6657ba50e702d84afb32fe846bed54fba1a77add/827ae/logo.svg descr: 快速、簡單且強大的網誌框架- class_name: 網站 class_desc: 值得推薦的網站 link_list: - name: Youtube link: https://www.youtube.com/ avatar: https://i.loli.net/2020/05/14/9ZkGg8v3azHJfM1.png descr: 視頻網站 - name: Weibo link: https://www.weibo.com/ avatar: https://i.loli.net/2020/05/14/TLJBum386vcnI1P.png descr: 中國最大社交分享平台 - name: Twitter link: https://twitter.com/ avatar: https://i.loli.net/2020/05/14/5VyHPQqR6LWF39a.png descr: 社交分享平台","categories":[{"name":"Hexo","slug":"Hexo","permalink":"https://blog.this52.cn/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://blog.this52.cn/tags/Hexo/"}]},{"title":"Mybatis#{}和${}区别","slug":"Mybatis#{}和${}区别","date":"2020-03-10T05:08:07.000Z","updated":"2020-09-27T07:24:20.000Z","comments":true,"path":"posts/da3e1361/","link":"","permalink":"https://blog.this52.cn/posts/da3e1361/","excerpt":"","text":"Mybatis的mapper.xml中有两种方式可以对方法形参取值，#{}和${}，这两个的区别用和应用场景有些区别。 本文简述区别 #{ }#{ }解析SQL脚本时，会使用PreparedStatement执行SQL语句，会将#{}作为占位符?，然后将形参取出赋值，可以有效防止SQL注入 ps： 12345&lt;select id=&quot;one&quot; resultType=&quot;com.example.pojo.Dept&quot;&gt; select * from dept where dept_id = #&#123;id&#125;;&lt;/select&gt; 12# 最后?占位符会加上引号select * from dept where dept_id = &#x27;1&#x27;; ${ }${ }解析SQL脚本时，会直接将形参变量取出，然后拼接在SQL语句中,这里用的也是PreparedStatement ps： 12345&lt;select id=&quot;one&quot; resultType=&quot;com.example.pojo.Dept&quot;&gt; select * from dept where dept_id = $&#123;id&#125;;&lt;/select&gt; 这时候就会存在一个问题，SQL注入，传入参数为&#39;&#39; or 1=1 类似恒等式 12select * from dept where dept_id = &#x27;&#x27; or 1=1;# 此时会查询出所有数据，同时对数据库也会造成压力 在只有一个形参时{ }里面可以不用写对应的形参变量名，比如{xxx}，但是建议相同 #{}方式是先用?代替参数将SQL语句进行预编译，然后再将参数中的内容替换进来，非法参数内容只会是一个参数，不会在为SQL命令的一部分，可以有效防止SQL注入 只能使用${}的场景由于#{}会给参数内容加上引号，有些时候需要字段、表名的情况下，SQL会出现问题。 ps: 排序时字段有引号，排序失效 表名有引号，直接报错 所以这些情况下只能使用${}。","categories":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.this52.cn/categories/Mybatis/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.this52.cn/tags/Mybatis/"},{"name":"SQL","slug":"SQL","permalink":"https://blog.this52.cn/tags/SQL/"}]}],"categories":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.this52.cn/categories/MongoDB/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/categories/Linux/"},{"name":"MQ","slug":"MQ","permalink":"https://blog.this52.cn/categories/MQ/"},{"name":"Nosql","slug":"Nosql","permalink":"https://blog.this52.cn/categories/Nosql/"},{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/categories/Java/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.this52.cn/categories/Spring/"},{"name":"Hexo","slug":"Hexo","permalink":"https://blog.this52.cn/categories/Hexo/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.this52.cn/categories/Mybatis/"}],"tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://blog.this52.cn/tags/MongoDB/"},{"name":"VirtualBox","slug":"VirtualBox","permalink":"https://blog.this52.cn/tags/VirtualBox/"},{"name":"MQ","slug":"MQ","permalink":"https://blog.this52.cn/tags/MQ/"},{"name":"RabiitMQ","slug":"RabiitMQ","permalink":"https://blog.this52.cn/tags/RabiitMQ/"},{"name":"Redis","slug":"Redis","permalink":"https://blog.this52.cn/tags/Redis/"},{"name":"Nosql","slug":"Nosql","permalink":"https://blog.this52.cn/tags/Nosql/"},{"name":"缓存","slug":"缓存","permalink":"https://blog.this52.cn/tags/%E7%BC%93%E5%AD%98/"},{"name":"Java","slug":"Java","permalink":"https://blog.this52.cn/tags/Java/"},{"name":"Shiro","slug":"Shiro","permalink":"https://blog.this52.cn/tags/Shiro/"},{"name":"安全框架","slug":"安全框架","permalink":"https://blog.this52.cn/tags/%E5%AE%89%E5%85%A8%E6%A1%86%E6%9E%B6/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.this52.cn/tags/Linux/"},{"name":"Docker","slug":"Docker","permalink":"https://blog.this52.cn/tags/Docker/"},{"name":"容器","slug":"容器","permalink":"https://blog.this52.cn/tags/%E5%AE%B9%E5%99%A8/"},{"name":"SPI","slug":"SPI","permalink":"https://blog.this52.cn/tags/SPI/"},{"name":"Spring","slug":"Spring","permalink":"https://blog.this52.cn/tags/Spring/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"https://blog.this52.cn/tags/SpringCloud/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://blog.this52.cn/tags/SpringBoot/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"https://blog.this52.cn/tags/jsDelivr/"},{"name":"GitHub","slug":"GitHub","permalink":"https://blog.this52.cn/tags/GitHub/"},{"name":"PicGo","slug":"PicGo","permalink":"https://blog.this52.cn/tags/PicGo/"},{"name":"图床","slug":"图床","permalink":"https://blog.this52.cn/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"CDN","slug":"CDN","permalink":"https://blog.this52.cn/tags/CDN/"},{"name":"Ngrok","slug":"Ngrok","permalink":"https://blog.this52.cn/tags/Ngrok/"},{"name":"Hexo","slug":"Hexo","permalink":"https://blog.this52.cn/tags/Hexo/"},{"name":"URL","slug":"URL","permalink":"https://blog.this52.cn/tags/URL/"},{"name":"Mybatis","slug":"Mybatis","permalink":"https://blog.this52.cn/tags/Mybatis/"},{"name":"SQL","slug":"SQL","permalink":"https://blog.this52.cn/tags/SQL/"}]}